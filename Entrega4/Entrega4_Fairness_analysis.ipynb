{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9ac9ac",
   "metadata": {},
   "source": [
    "# PARTE 1: ANÁLISIS ÉTICO Y DE FAIRNESS\n",
    "\n",
    "## Entrega 4 - ConcentraciónAI\n",
    "\n",
    "Este notebook implementa un análisis completo de fairness y consideraciones éticas para los modelos entrenados en la Entrega 3 utilizando el dataset del Titanic.\n",
    "\n",
    "### Objetivos:\n",
    "1. **Evaluación de Sesgos Algorítmicos**: Implementar métricas cuantitativas de fairness\n",
    "2. **Análisis Interseccional**: Examinar disparidades entre múltiples grupos protegidos\n",
    "3. **Simulación de Decisiones**: Evaluar el impacto ético en escenarios reales\n",
    "4. **Reflexión Ética**: Análisis profundo de dilemas éticos y responsabilidad\n",
    "\n",
    "### Contexto Ético\n",
    "El dataset del Titanic representa un evento histórico real donde las decisiones de vida o muerte estuvieron influenciadas por factores socioeconómicos, género y edad. Al construir modelos predictivos sobre estos datos, debemos ser conscientes de que:\n",
    "- Los patrones reflejan desigualdades históricas\n",
    "- Los modelos pueden perpetuar o amplificar estos sesgos\n",
    "- Las decisiones algorítmicas tienen implicaciones éticas profundas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6bfb506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fairlearn disponible\n",
      "⚠️ AIF360 no disponible - implementaremos métricas manualmente\n",
      "Librerías importadas exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías básicas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Librerías para visualización\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Librerías de machine learning\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    brier_score_loss\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Intentar importar librerías de fairness (pueden no estar instaladas)\n",
    "try:\n",
    "    from fairlearn.metrics import (\n",
    "        demographic_parity_ratio,\n",
    "        demographic_parity_difference,\n",
    "        equalized_odds_ratio,\n",
    "        equalized_odds_difference,\n",
    "        MetricFrame\n",
    "    )\n",
    "    fairlearn_available = True\n",
    "    print(\"✓ Fairlearn disponible\")\n",
    "except ImportError:\n",
    "    fairlearn_available = False\n",
    "    print(\"⚠️ Fairlearn no disponible - implementaremos métricas manualmente\")\n",
    "\n",
    "try:\n",
    "    from aif360.metrics import BinaryLabelDatasetMetric\n",
    "    from aif360.algorithms.preprocessing import Reweighing\n",
    "    from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "    aif360_available = True\n",
    "    print(\"✓ AIF360 disponible\")\n",
    "except ImportError:\n",
    "    aif360_available = False\n",
    "    print(\"⚠️ AIF360 no disponible - implementaremos métricas manualmente\")\n",
    "\n",
    "print(\"Librerías importadas exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6b1d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "Forma del dataset: (891, 36)\n",
      "\n",
      "Columnas disponibles:\n",
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Has_Cabin', 'Age_Group', 'Title', 'FamilySize', 'IsAlone', 'AgeGroup', 'FarePerPerson', 'FarePerPerson_Quintile', 'TicketFrequency', 'TicketFreq_Category', 'CabinDeck', 'Mother', 'NameLength', 'NameLength_Category', 'NameLength_Quintile', 'TicketPrefix', 'TicketPrefix_Category', 'Fare_log', 'FarePerPerson_log', 'Age_sqrt', 'NameLength_sqrt', 'FamilySize_Category', 'IsMinor', 'DeckCategory']\n",
      "\n",
      "=== ANÁLISIS DEMOGRÁFICO ===\n",
      "Distribución por Sexo:\n",
      "Sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución por Clase:\n",
      "Pclass\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución por Edad (grupos):\n",
      "Age_Group\n",
      "Adult    769\n",
      "Child    100\n",
      "Elder     22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Tasa de supervivencia general: 0.384 (38.4%)\n",
      "\n",
      "Primeras 5 filas del dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>NameLength_Quintile</th>\n",
       "      <th>TicketPrefix</th>\n",
       "      <th>TicketPrefix_Category</th>\n",
       "      <th>Fare_log</th>\n",
       "      <th>FarePerPerson_log</th>\n",
       "      <th>Age_sqrt</th>\n",
       "      <th>NameLength_sqrt</th>\n",
       "      <th>FamilySize_Category</th>\n",
       "      <th>IsMinor</th>\n",
       "      <th>DeckCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>Q2</td>\n",
       "      <td>A_</td>\n",
       "      <td>Other</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>4.690416</td>\n",
       "      <td>4.795832</td>\n",
       "      <td>Pequeña</td>\n",
       "      <td>0</td>\n",
       "      <td>Inferior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>PC</td>\n",
       "      <td>PC</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>6.164414</td>\n",
       "      <td>7.141428</td>\n",
       "      <td>Pequeña</td>\n",
       "      <td>0</td>\n",
       "      <td>Superior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>Q2</td>\n",
       "      <td>STON_O</td>\n",
       "      <td>Other</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>5.099020</td>\n",
       "      <td>4.690416</td>\n",
       "      <td>Solo</td>\n",
       "      <td>0</td>\n",
       "      <td>Inferior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>3.316003</td>\n",
       "      <td>5.916080</td>\n",
       "      <td>6.633250</td>\n",
       "      <td>Pequeña</td>\n",
       "      <td>0</td>\n",
       "      <td>Superior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>Q3</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>5.916080</td>\n",
       "      <td>4.898979</td>\n",
       "      <td>Solo</td>\n",
       "      <td>0</td>\n",
       "      <td>Inferior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare  ... NameLength_Quintile TicketPrefix  \\\n",
       "0      0         A/5 21171   7.2500  ...                  Q2           A_   \n",
       "1      0          PC 17599  71.2833  ...                  Q5           PC   \n",
       "2      0  STON/O2. 3101282   7.9250  ...                  Q2       STON_O   \n",
       "3      0            113803  53.1000  ...                  Q5      Numeric   \n",
       "4      0            373450   8.0500  ...                  Q3      Numeric   \n",
       "\n",
       "   TicketPrefix_Category  Fare_log FarePerPerson_log  Age_sqrt  \\\n",
       "0                  Other  2.110213          2.110213  4.690416   \n",
       "1                     PC  4.280593          4.280593  6.164414   \n",
       "2                  Other  2.188856          2.188856  5.099020   \n",
       "3                Numeric  3.990834          3.316003  5.916080   \n",
       "4                Numeric  2.202765          2.202765  5.916080   \n",
       "\n",
       "   NameLength_sqrt FamilySize_Category  IsMinor DeckCategory  \n",
       "0         4.795832             Pequeña        0     Inferior  \n",
       "1         7.141428             Pequeña        0     Superior  \n",
       "2         4.690416                Solo        0     Inferior  \n",
       "3         6.633250             Pequeña        0     Superior  \n",
       "4         4.898979                Solo        0     Inferior  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset procesado de la Entrega 2\n",
    "print(\"Cargando datos...\")\n",
    "df = pd.read_csv('../Entrega2/data/Titanic_Dataset_Featured.csv')\n",
    "\n",
    "# Verificar la estructura del dataset\n",
    "print(f\"Forma del dataset: {df.shape}\")\n",
    "print(\"\\nColumnas disponibles:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Mostrar información básica sobre grupos protegidos\n",
    "print(\"\\n=== ANÁLISIS DEMOGRÁFICO ===\")\n",
    "print(f\"Distribución por Sexo:\")\n",
    "print(df['Sex'].value_counts())\n",
    "print(f\"\\nDistribución por Clase:\")\n",
    "print(df['Pclass'].value_counts())\n",
    "print(f\"\\nDistribución por Edad (grupos):\")\n",
    "df['Age_Group'] = pd.cut(df['Age'], bins=[0, 16, 60, 100], labels=['Child', 'Adult', 'Elder'])\n",
    "print(df['Age_Group'].value_counts())\n",
    "\n",
    "# Tasa de supervivencia general\n",
    "survival_rate = df['Survived'].mean()\n",
    "print(f\"\\nTasa de supervivencia general: {survival_rate:.3f} ({survival_rate*100:.1f}%)\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "print(\"\\nPrimeras 5 filas del dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0257d7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook configurado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Configurar el notebook para trabajar correctamente\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Configurar estilo de plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configurar plotly para mejor visualización\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"Notebook configurado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96eb7846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelos entrenados...\n",
      "❌ Error cargando RandomForest: invalid load key, '\\x0d'.\n",
      "❌ Error cargando LogisticRegression: invalid load key, '\\x0b'.\n",
      "❌ Error cargando SVM: invalid load key, '\\x0b'.\n",
      "❌ Error cargando RandomForest: invalid load key, '\\x0d'.\n",
      "❌ Error cargando LogisticRegression: invalid load key, '\\x0b'.\n",
      "❌ Error cargando SVM: invalid load key, '\\x0b'.\n",
      "✓ XGBoost cargado exitosamente\n",
      "❌ Error cargando XGBoost: invalid load key, '\\x03'.\n",
      "\n",
      "Modelos cargados: ['XGBoost']\n",
      "Resultados disponibles: []\n",
      "✓ XGBoost cargado exitosamente\n",
      "❌ Error cargando XGBoost: invalid load key, '\\x03'.\n",
      "\n",
      "Modelos cargados: ['XGBoost']\n",
      "Resultados disponibles: []\n"
     ]
    }
   ],
   "source": [
    "# Cargar los modelos entrenados de la Entrega 3\n",
    "models_path = '../Entrega3/models/'\n",
    "\n",
    "# Diccionario para almacenar los modelos\n",
    "models = {}\n",
    "model_results = {}\n",
    "\n",
    "# Lista de modelos disponibles\n",
    "model_files = {\n",
    "    'RandomForest': 'randomforest_model.pkl',\n",
    "    'LogisticRegression': 'logisticregression_model.pkl', \n",
    "    'SVM': 'svm_model.pkl',\n",
    "    'XGBoost': 'xgboost_model.pkl'\n",
    "}\n",
    "\n",
    "# Cargar cada modelo\n",
    "print(\"Cargando modelos entrenados...\")\n",
    "for name, filename in model_files.items():\n",
    "    try:\n",
    "        model_path = os.path.join(models_path, filename)\n",
    "        with open(model_path, 'rb') as f:\n",
    "            models[name] = pickle.load(f)\n",
    "        print(f\"✓ {name} cargado exitosamente\")\n",
    "        \n",
    "        # Cargar resultados si están disponibles\n",
    "        results_file = filename.replace('_model.pkl', '_results.pkl')\n",
    "        results_path = os.path.join(models_path, results_file)\n",
    "        if os.path.exists(results_path):\n",
    "            with open(results_path, 'rb') as f:\n",
    "                model_results[name] = pickle.load(f)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error cargando {name}: {e}\")\n",
    "\n",
    "print(f\"\\nModelos cargados: {list(models.keys())}\")\n",
    "print(f\"Resultados disponibles: {list(model_results.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab199023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparación de datos completada\n",
      "Características utilizadas: ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'FarePerPerson', 'Sex_encoded', 'Embarked_encoded', 'Title_encoded', 'Has_Cabin', 'IsAlone']\n",
      "Forma de X: (891, 12)\n",
      "Forma de y: (891,)\n",
      "\n",
      "Grupos protegidos definidos: ['Gender', 'Class', 'Age_Group']\n"
     ]
    }
   ],
   "source": [
    "# Preparar los datos para el análisis de fairness\n",
    "# Seleccionar las características más importantes (basado en análisis previos)\n",
    "\n",
    "# Características numéricas principales\n",
    "numeric_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'FarePerPerson']\n",
    "\n",
    "# Codificar características categóricas\n",
    "df_fairness = df.copy()\n",
    "\n",
    "# Codificar sexo (0: female, 1: male)\n",
    "df_fairness['Sex_encoded'] = (df_fairness['Sex'] == 'male').astype(int)\n",
    "\n",
    "# Codificar embarque\n",
    "embarked_encoder = LabelEncoder()\n",
    "df_fairness['Embarked_encoded'] = embarked_encoder.fit_transform(df_fairness['Embarked'].fillna('S'))\n",
    "\n",
    "# Codificar título\n",
    "title_encoder = LabelEncoder()  \n",
    "df_fairness['Title_encoded'] = title_encoder.fit_transform(df_fairness['Title'])\n",
    "\n",
    "# Crear características finales para el modelo\n",
    "feature_columns = numeric_features + ['Sex_encoded', 'Embarked_encoded', 'Title_encoded', 'Has_Cabin', 'IsAlone']\n",
    "\n",
    "# Preparar X e y\n",
    "X = df_fairness[feature_columns].fillna(0)\n",
    "y = df_fairness['Survived']\n",
    "\n",
    "print(\"Preparación de datos completada\")\n",
    "print(f\"Características utilizadas: {feature_columns}\")\n",
    "print(f\"Forma de X: {X.shape}\")\n",
    "print(f\"Forma de y: {y.shape}\")\n",
    "\n",
    "# Definir grupos protegidos para análisis de fairness\n",
    "protected_attrs = {\n",
    "    'Gender': df_fairness['Sex'],\n",
    "    'Class': df_fairness['Pclass'],\n",
    "    'Age_Group': df_fairness['Age_Group']\n",
    "}\n",
    "\n",
    "print(f\"\\nGrupos protegidos definidos: {list(protected_attrs.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219fc3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Random Forest: 0.788\n",
      "Forma de los datos de prueba: (179, 12)\n",
      "\n",
      "Dataset de prueba preparado con 179 muestras\n",
      "Distribución de predicciones:\n",
      "Predicted\n",
      "0    112\n",
      "1     67\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Entrenar un modelo Random Forest para análisis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Entrenar Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener predicciones y probabilidades\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_probabilities = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluación básica\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f\"Accuracy del Random Forest: {accuracy:.3f}\")\n",
    "print(f\"Forma de los datos de prueba: {X_test.shape}\")\n",
    "\n",
    "# Guardar el modelo entrenado en nuestro diccionario\n",
    "models['RandomForest_Current'] = rf_model\n",
    "\n",
    "# Crear DataFrame con datos de prueba y resultados\n",
    "test_indices = X_test.index\n",
    "df_test = df_fairness.loc[test_indices].copy()\n",
    "df_test['Predicted'] = rf_predictions\n",
    "df_test['Probability'] = rf_probabilities\n",
    "\n",
    "print(f\"\\nDataset de prueba preparado con {len(df_test)} muestras\")\n",
    "print(\"Distribución de predicciones:\")\n",
    "print(df_test['Predicted'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b88b4360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase FairnessAnalyzer implementada exitosamente\n"
     ]
    }
   ],
   "source": [
    "class FairnessAnalyzer:\n",
    "    \"\"\"\n",
    "    Clase para realizar análisis completo de fairness en modelos de ML\n",
    "    Implementa métricas de disparidad demográfica, igualdad de oportunidad,\n",
    "    odds equalizados y calibración por grupo.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, true_col='Survived', pred_col='Predicted', prob_col='Probability'):\n",
    "        self.df = df.copy()\n",
    "        self.true_col = true_col\n",
    "        self.pred_col = pred_col\n",
    "        self.prob_col = prob_col\n",
    "        \n",
    "    def demographic_parity(self, group_col):\n",
    "        \"\"\"\n",
    "        Calcula disparidad demográfica (Statistical Parity)\n",
    "        P(Ŷ=1|G=0) ≈ P(Ŷ=1|G=1)\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        groups = self.df[group_col].unique()\n",
    "        \n",
    "        for group in groups:\n",
    "            group_mask = self.df[group_col] == group\n",
    "            group_data = self.df[group_mask]\n",
    "            \n",
    "            pred_rate = group_data[self.pred_col].mean()\n",
    "            total_group = len(group_data)\n",
    "            \n",
    "            results[group] = {\n",
    "                'positive_prediction_rate': pred_rate,\n",
    "                'count': total_group\n",
    "            }\n",
    "        \n",
    "        # Calcular ratios y diferencias\n",
    "        groups_list = list(groups)\n",
    "        if len(groups_list) >= 2:\n",
    "            group1, group2 = groups_list[0], groups_list[1]\n",
    "            rate1 = results[group1]['positive_prediction_rate']\n",
    "            rate2 = results[group2]['positive_prediction_rate']\n",
    "            \n",
    "            results['demographic_parity_ratio'] = min(rate1, rate2) / max(rate1, rate2)\n",
    "            results['demographic_parity_difference'] = abs(rate1 - rate2)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def equal_opportunity(self, group_col):\n",
    "        \"\"\"\n",
    "        Calcula igualdad de oportunidad (Equal Opportunity)\n",
    "        P(Ŷ=1|Y=1,G=0) ≈ P(Ŷ=1|Y=1,G=1)\n",
    "        True Positive Rate por grupo\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        groups = self.df[group_col].unique()\n",
    "        \n",
    "        for group in groups:\n",
    "            group_mask = self.df[group_col] == group\n",
    "            positive_actual = self.df[group_mask & (self.df[self.true_col] == 1)]\n",
    "            \n",
    "            if len(positive_actual) > 0:\n",
    "                tpr = positive_actual[self.pred_col].mean()\n",
    "                total_positives = len(positive_actual)\n",
    "                true_positives = positive_actual[self.pred_col].sum()\n",
    "            else:\n",
    "                tpr = 0\n",
    "                total_positives = 0\n",
    "                true_positives = 0\n",
    "            \n",
    "            results[group] = {\n",
    "                'true_positive_rate': tpr,\n",
    "                'true_positives': true_positives,\n",
    "                'total_actual_positives': total_positives\n",
    "            }\n",
    "        \n",
    "        # Calcular diferencias\n",
    "        groups_list = list(groups)\n",
    "        if len(groups_list) >= 2:\n",
    "            group1, group2 = groups_list[0], groups_list[1]\n",
    "            tpr1 = results[group1]['true_positive_rate']\n",
    "            tpr2 = results[group2]['true_positive_rate']\n",
    "            \n",
    "            if max(tpr1, tpr2) > 0:\n",
    "                results['equal_opportunity_ratio'] = min(tpr1, tpr2) / max(tpr1, tpr2)\n",
    "            else:\n",
    "                results['equal_opportunity_ratio'] = 1.0\n",
    "            results['equal_opportunity_difference'] = abs(tpr1 - tpr2)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def equalized_odds(self, group_col):\n",
    "        \"\"\"\n",
    "        Calcula odds equalizados (Equalized Odds)\n",
    "        TPR y FPR similares entre grupos\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        groups = self.df[group_col].unique()\n",
    "        \n",
    "        for group in groups:\n",
    "            group_mask = self.df[group_col] == group\n",
    "            group_data = self.df[group_mask]\n",
    "            \n",
    "            # True Positive Rate\n",
    "            actual_positives = group_data[group_data[self.true_col] == 1]\n",
    "            if len(actual_positives) > 0:\n",
    "                tpr = actual_positives[self.pred_col].mean()\n",
    "            else:\n",
    "                tpr = 0\n",
    "            \n",
    "            # False Positive Rate\n",
    "            actual_negatives = group_data[group_data[self.true_col] == 0]\n",
    "            if len(actual_negatives) > 0:\n",
    "                fpr = actual_negatives[self.pred_col].mean()\n",
    "            else:\n",
    "                fpr = 0\n",
    "            \n",
    "            results[group] = {\n",
    "                'true_positive_rate': tpr,\n",
    "                'false_positive_rate': fpr,\n",
    "                'actual_positives': len(actual_positives),\n",
    "                'actual_negatives': len(actual_negatives)\n",
    "            }\n",
    "        \n",
    "        # Calcular diferencias\n",
    "        groups_list = list(groups)\n",
    "        if len(groups_list) >= 2:\n",
    "            group1, group2 = groups_list[0], groups_list[1]\n",
    "            tpr_diff = abs(results[group1]['true_positive_rate'] - results[group2]['true_positive_rate'])\n",
    "            fpr_diff = abs(results[group1]['false_positive_rate'] - results[group2]['false_positive_rate'])\n",
    "            \n",
    "            results['tpr_difference'] = tpr_diff\n",
    "            results['fpr_difference'] = fpr_diff\n",
    "            results['equalized_odds_satisfied'] = (tpr_diff < 0.1) and (fpr_diff < 0.1)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def calibration_by_group(self, group_col, n_bins=10):\n",
    "        \"\"\"\n",
    "        Analiza calibración por grupo\n",
    "        P(Y=1|Ŷ=p,G=g) ≈ p para todo g\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        groups = self.df[group_col].unique()\n",
    "        \n",
    "        for group in groups:\n",
    "            group_mask = self.df[group_col] == group\n",
    "            group_data = self.df[group_mask]\n",
    "            \n",
    "            if len(group_data) > 0:\n",
    "                y_true = group_data[self.true_col]\n",
    "                y_prob = group_data[self.prob_col]\n",
    "                \n",
    "                # Usar calibration_curve de sklearn\n",
    "                fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "                    y_true, y_prob, n_bins=min(n_bins, len(group_data)//2)\n",
    "                )\n",
    "                \n",
    "                # Calcular Brier Score\n",
    "                brier_score = brier_score_loss(y_true, y_prob)\n",
    "                \n",
    "                results[group] = {\n",
    "                    'fraction_of_positives': fraction_of_positives,\n",
    "                    'mean_predicted_value': mean_predicted_value,\n",
    "                    'brier_score': brier_score,\n",
    "                    'count': len(group_data)\n",
    "                }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def comprehensive_analysis(self, group_col):\n",
    "        \"\"\"\n",
    "        Realiza análisis completo de fairness para un grupo\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ANÁLISIS DE FAIRNESS: {group_col.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # 1. Disparidad Demográfica\n",
    "        dp_results = self.demographic_parity(group_col)\n",
    "        print(f\"\\n1. DISPARIDAD DEMOGRÁFICA (Statistical Parity)\")\n",
    "        print(\"-\" * 50)\n",
    "        for group in self.df[group_col].unique():\n",
    "            rate = dp_results[group]['positive_prediction_rate']\n",
    "            count = dp_results[group]['count']\n",
    "            print(f\"{group}: {rate:.3f} ({rate*100:.1f}%) - N={count}\")\n",
    "        \n",
    "        if 'demographic_parity_ratio' in dp_results:\n",
    "            ratio = dp_results['demographic_parity_ratio']\n",
    "            diff = dp_results['demographic_parity_difference']\n",
    "            print(f\"Ratio: {ratio:.3f} | Diferencia: {diff:.3f}\")\n",
    "            if ratio < 0.8:\n",
    "                print(\"⚠️  SESGO DETECTADO: Disparidad demográfica significativa\")\n",
    "            else:\n",
    "                print(\"✓ Disparidad demográfica aceptable\")\n",
    "        \n",
    "        # 2. Igualdad de Oportunidad\n",
    "        eo_results = self.equal_opportunity(group_col)\n",
    "        print(f\"\\n2. IGUALDAD DE OPORTUNIDAD (Equal Opportunity)\")\n",
    "        print(\"-\" * 50)\n",
    "        for group in self.df[group_col].unique():\n",
    "            tpr = eo_results[group]['true_positive_rate']\n",
    "            tp = eo_results[group]['true_positives']\n",
    "            total = eo_results[group]['total_actual_positives']\n",
    "            print(f\"{group}: TPR={tpr:.3f} ({tp}/{total})\")\n",
    "        \n",
    "        if 'equal_opportunity_ratio' in eo_results:\n",
    "            ratio = eo_results['equal_opportunity_ratio']\n",
    "            diff = eo_results['equal_opportunity_difference']\n",
    "            print(f\"Ratio: {ratio:.3f} | Diferencia: {diff:.3f}\")\n",
    "            if ratio < 0.8:\n",
    "                print(\"⚠️  SESGO DETECTADO: Desigualdad de oportunidad significativa\")\n",
    "            else:\n",
    "                print(\"✓ Igualdad de oportunidad aceptable\")\n",
    "        \n",
    "        # 3. Odds Equalizados\n",
    "        eq_results = self.equalized_odds(group_col)\n",
    "        print(f\"\\n3. ODDS EQUALIZADOS (Equalized Odds)\")\n",
    "        print(\"-\" * 50)\n",
    "        for group in self.df[group_col].unique():\n",
    "            tpr = eq_results[group]['true_positive_rate']\n",
    "            fpr = eq_results[group]['false_positive_rate']\n",
    "            print(f\"{group}: TPR={tpr:.3f}, FPR={fpr:.3f}\")\n",
    "        \n",
    "        if 'equalized_odds_satisfied' in eq_results:\n",
    "            satisfied = eq_results['equalized_odds_satisfied']\n",
    "            tpr_diff = eq_results['tpr_difference']\n",
    "            fpr_diff = eq_results['fpr_difference']\n",
    "            print(f\"TPR diff: {tpr_diff:.3f} | FPR diff: {fpr_diff:.3f}\")\n",
    "            if satisfied:\n",
    "                print(\"✓ Odds equalizados satisfechos\")\n",
    "            else:\n",
    "                print(\"⚠️  SESGO DETECTADO: Odds no equalizados\")\n",
    "        \n",
    "        # 4. Calibración por Grupo\n",
    "        cal_results = self.calibration_by_group(group_col)\n",
    "        print(f\"\\n4. CALIBRACIÓN POR GRUPO\")\n",
    "        print(\"-\" * 50)\n",
    "        for group in self.df[group_col].unique():\n",
    "            brier = cal_results[group]['brier_score']\n",
    "            count = cal_results[group]['count']\n",
    "            print(f\"{group}: Brier Score={brier:.3f} (N={count})\")\n",
    "        \n",
    "        return {\n",
    "            'demographic_parity': dp_results,\n",
    "            'equal_opportunity': eo_results,\n",
    "            'equalized_odds': eq_results,\n",
    "            'calibration': cal_results\n",
    "        }\n",
    "\n",
    "print(\"Clase FairnessAnalyzer implementada exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e611b0ff",
   "metadata": {},
   "source": [
    "## 1.1 Evaluación de Sesgos Algorítmicos\n",
    "\n",
    "### A. Análisis Cuantitativo de Fairness\n",
    "\n",
    "En esta sección implementamos y analizamos las siguientes métricas de fairness para cada grupo protegido (género, clase, edad):\n",
    "\n",
    "1. **DISPARIDAD DEMOGRÁFICA (Statistical Parity)**: P(Ŷ=1|G=0) ≈ P(Ŷ=1|G=1)\n",
    "2. **IGUALDAD DE OPORTUNIDAD (Equal Opportunity)**: P(Ŷ=1|Y=1,G=0) ≈ P(Ŷ=1|Y=1,G=1)\n",
    "3. **ODDS EQUALIZADOS (Equalized Odds)**: TPR y FPR similares entre grupos\n",
    "4. **CALIBRACIÓN POR GRUPO**: P(Y=1|Ŷ=p,G=g) ≈ p para todo g\n",
    "\n",
    "Las métricas se evalúan usando umbrales estándar:\n",
    "- **Ratio < 0.8**: Indica sesgo significativo\n",
    "- **Diferencia > 0.1**: Sugiere disparidad notable\n",
    "- **Brier Score**: Menor es mejor para calibración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea1b7721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INICIANDO ANÁLISIS CUANTITATIVO DE FAIRNESS\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "ANÁLISIS DE FAIRNESS: SEX\n",
      "============================================================\n",
      "\n",
      "1. DISPARIDAD DEMOGRÁFICA (Statistical Parity)\n",
      "--------------------------------------------------\n",
      "male: 0.186 (18.6%) - N=118\n",
      "female: 0.738 (73.8%) - N=61\n",
      "Ratio: 0.253 | Diferencia: 0.551\n",
      "⚠️  SESGO DETECTADO: Disparidad demográfica significativa\n",
      "\n",
      "2. IGUALDAD DE OPORTUNIDAD (Equal Opportunity)\n",
      "--------------------------------------------------\n",
      "male: TPR=0.417 (10/24)\n",
      "female: TPR=0.867 (39/45)\n",
      "Ratio: 0.481 | Diferencia: 0.450\n",
      "⚠️  SESGO DETECTADO: Desigualdad de oportunidad significativa\n",
      "\n",
      "3. ODDS EQUALIZADOS (Equalized Odds)\n",
      "--------------------------------------------------\n",
      "male: TPR=0.417, FPR=0.128\n",
      "female: TPR=0.867, FPR=0.375\n",
      "TPR diff: 0.450 | FPR diff: 0.247\n",
      "⚠️  SESGO DETECTADO: Odds no equalizados\n",
      "\n",
      "4. CALIBRACIÓN POR GRUPO\n",
      "--------------------------------------------------\n",
      "male: Brier Score=0.148 (N=118)\n",
      "female: Brier Score=0.140 (N=61)\n"
     ]
    }
   ],
   "source": [
    "# Crear instancia del analizador de fairness\n",
    "analyzer = FairnessAnalyzer(df_test)\n",
    "\n",
    "# ANÁLISIS POR GÉNERO\n",
    "print(\"INICIANDO ANÁLISIS CUANTITATIVO DE FAIRNESS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Realizar análisis completo por género\n",
    "gender_results = analyzer.comprehensive_analysis('Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a337d01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANÁLISIS DE FAIRNESS: PCLASS\n",
      "============================================================\n",
      "\n",
      "1. DISPARIDAD DEMOGRÁFICA (Statistical Parity)\n",
      "--------------------------------------------------\n",
      "3: 0.180 (18.0%) - N=100\n",
      "2: 0.559 (55.9%) - N=34\n",
      "1: 0.667 (66.7%) - N=45\n",
      "Ratio: 0.322 | Diferencia: 0.379\n",
      "⚠️  SESGO DETECTADO: Disparidad demográfica significativa\n",
      "\n",
      "2. IGUALDAD DE OPORTUNIDAD (Equal Opportunity)\n",
      "--------------------------------------------------\n",
      "3: TPR=0.500 (12/24)\n",
      "2: TPR=0.900 (18/20)\n",
      "1: TPR=0.760 (19/25)\n",
      "Ratio: 0.556 | Diferencia: 0.400\n",
      "⚠️  SESGO DETECTADO: Desigualdad de oportunidad significativa\n",
      "\n",
      "3. ODDS EQUALIZADOS (Equalized Odds)\n",
      "--------------------------------------------------\n",
      "3: TPR=0.500, FPR=0.079\n",
      "2: TPR=0.900, FPR=0.071\n",
      "1: TPR=0.760, FPR=0.550\n",
      "TPR diff: 0.400 | FPR diff: 0.008\n",
      "⚠️  SESGO DETECTADO: Odds no equalizados\n",
      "\n",
      "4. CALIBRACIÓN POR GRUPO\n",
      "--------------------------------------------------\n",
      "3: Brier Score=0.140 (N=100)\n",
      "2: Brier Score=0.103 (N=34)\n",
      "1: Brier Score=0.189 (N=45)\n"
     ]
    }
   ],
   "source": [
    "# ANÁLISIS POR CLASE SOCIAL\n",
    "class_results = analyzer.comprehensive_analysis('Pclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b105a7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANÁLISIS DE FAIRNESS: AGE_GROUP\n",
      "============================================================\n",
      "\n",
      "1. DISPARIDAD DEMOGRÁFICA (Statistical Parity)\n",
      "--------------------------------------------------\n",
      "Adult: 0.349 (34.9%) - N=149\n",
      "Child: 0.542 (54.2%) - N=24\n",
      "Elder: 0.333 (33.3%) - N=6\n",
      "Ratio: 0.644 | Diferencia: 0.193\n",
      "⚠️  SESGO DETECTADO: Disparidad demográfica significativa\n",
      "\n",
      "2. IGUALDAD DE OPORTUNIDAD (Equal Opportunity)\n",
      "--------------------------------------------------\n",
      "Adult: TPR=0.673 (37/55)\n",
      "Child: TPR=0.917 (11/12)\n",
      "Elder: TPR=0.500 (1/2)\n",
      "Ratio: 0.734 | Diferencia: 0.244\n",
      "⚠️  SESGO DETECTADO: Desigualdad de oportunidad significativa\n",
      "\n",
      "3. ODDS EQUALIZADOS (Equalized Odds)\n",
      "--------------------------------------------------\n",
      "Adult: TPR=0.673, FPR=0.160\n",
      "Child: TPR=0.917, FPR=0.167\n",
      "Elder: TPR=0.500, FPR=0.250\n",
      "TPR diff: 0.244 | FPR diff: 0.007\n",
      "⚠️  SESGO DETECTADO: Odds no equalizados\n",
      "\n",
      "4. CALIBRACIÓN POR GRUPO\n",
      "--------------------------------------------------\n",
      "Adult: Brier Score=0.151 (N=149)\n",
      "Child: Brier Score=0.088 (N=24)\n",
      "Elder: Brier Score=0.233 (N=6)\n"
     ]
    }
   ],
   "source": [
    "# ANÁLISIS POR GRUPOS DE EDAD\n",
    "age_results = analyzer.comprehensive_analysis('Age_Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f3fb2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#FF6B6B"
         },
         "name": "Pred Rate Sex",
         "showlegend": false,
         "type": "bar",
         "x": [
          "male",
          "female"
         ],
         "xaxis": "x",
         "y": [
          0.1864406779661017,
          0.7377049180327869
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#4ECDC4"
         },
         "name": "Pred Rate Pclass",
         "showlegend": false,
         "type": "bar",
         "x": [
          "3",
          "2",
          "1"
         ],
         "xaxis": "x2",
         "y": [
          0.18,
          0.5588235294117647,
          0.6666666666666666
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#45B7D1"
         },
         "name": "Pred Rate Age_Group",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Adult",
          "Child",
          "Elder"
         ],
         "xaxis": "x3",
         "y": [
          0.348993288590604,
          0.5416666666666666,
          0.3333333333333333
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#2ECC71"
         },
         "name": "TPR",
         "showlegend": false,
         "type": "bar",
         "x": [
          "male",
          "female"
         ],
         "xaxis": "x4",
         "y": [
          0.4166666666666667,
          0.8666666666666667
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#E74C3C"
         },
         "name": "FPR",
         "showlegend": false,
         "type": "bar",
         "x": [
          "3",
          "2",
          "1"
         ],
         "xaxis": "x5",
         "y": [
          0.07894736842105263,
          0.07142857142857142,
          0.55
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "#9B59B6"
         },
         "name": "Brier Score",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Adult",
          "Child",
          "Elder"
         ],
         "xaxis": "x6",
         "y": [
          0.15070859885414767,
          0.08776153649998981,
          0.23337578245109403
         ],
         "yaxis": "y6"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Disparidad Demográfica por Género",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Disparidad Demográfica por Clase",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Disparidad Demográfica por Edad",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "True Positive Rate por Grupo",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "False Positive Rate por Grupo",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Brier Score (Calibración)",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "showarrow": false,
          "text": "Umbral crítico",
          "x": 1,
          "xanchor": "right",
          "xref": "x domain",
          "y": 0.8,
          "yanchor": "bottom",
          "yref": "y"
         },
         {
          "showarrow": false,
          "text": "Umbral crítico",
          "x": 1,
          "xanchor": "right",
          "xref": "x2 domain",
          "y": 0.8,
          "yanchor": "bottom",
          "yref": "y2"
         },
         {
          "showarrow": false,
          "text": "Umbral crítico",
          "x": 1,
          "xanchor": "right",
          "xref": "x3 domain",
          "y": 0.8,
          "yanchor": "bottom",
          "yref": "y3"
         }
        ],
        "font": {
         "size": 12
        },
        "height": 600,
        "shapes": [
         {
          "line": {
           "color": "red",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 0.8,
          "y1": 0.8,
          "yref": "y"
         },
         {
          "line": {
           "color": "red",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x2 domain",
          "y0": 0.8,
          "y1": 0.8,
          "yref": "y2"
         },
         {
          "line": {
           "color": "red",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x3 domain",
          "y0": 0.8,
          "y1": 0.8,
          "yref": "y3"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "📊 Dashboard de Métricas de Fairness",
         "x": 0.5
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.2888888888888889
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.35555555555555557,
          0.6444444444444445
         ]
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.7111111111111111,
          1
         ]
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0,
          0.2888888888888889
         ]
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0.35555555555555557,
          0.6444444444444445
         ]
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.7111111111111111,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.375
         ]
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.375
         ]
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.375
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorbar": {
          "title": {
           "text": "Proporción"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(165,0,38)"
          ],
          [
           0.1,
           "rgb(215,48,39)"
          ],
          [
           0.2,
           "rgb(244,109,67)"
          ],
          [
           0.3,
           "rgb(253,174,97)"
          ],
          [
           0.4,
           "rgb(254,224,144)"
          ],
          [
           0.5,
           "rgb(255,255,191)"
          ],
          [
           0.6,
           "rgb(224,243,248)"
          ],
          [
           0.7,
           "rgb(171,217,233)"
          ],
          [
           0.8,
           "rgb(116,173,209)"
          ],
          [
           0.9,
           "rgb(69,117,180)"
          ],
          [
           1,
           "rgb(49,54,149)"
          ]
         ],
         "text": {
          "bdata": "AAAAAAAAAAARERERERGxPwAAAAAAAAAA3t3d3d3d7T8AAAAAAAAAABzHcRzHcaw/AAAAAAAAAACO4ziO4zjuP7dt27Zt29Y/kiRJkiRJwj/btm3btm3LP5IkSZIkSdI/MzMzMzMz0z9VVVVVVVXVP5qZmZmZmck/VVVVVVVVxT8AAAAAAADqPwAAAAAAAAAAAAAAAAAAwD8AAAAAAACwP6uqqqqqquo/HMdxHMdxnD9VVVVVVVW1PxzHcRzHcaw/",
          "dtype": "f8",
          "shape": "6, 4"
         },
         "texttemplate": "%{text:.2f}",
         "type": "heatmap",
         "x": [
          "Real=0, Pred=0",
          "Real=0, Pred=1",
          "Real=1, Pred=0",
          "Real=1, Pred=1"
         ],
         "y": [
          "female, Clase 1",
          "female, Clase 2",
          "female, Clase 3",
          "male, Clase 1",
          "male, Clase 2",
          "male, Clase 3"
         ],
         "z": {
          "bdata": "AAAAAAAAAAARERERERGxPwAAAAAAAAAA3t3d3d3d7T8AAAAAAAAAABzHcRzHcaw/AAAAAAAAAACO4ziO4zjuP7dt27Zt29Y/kiRJkiRJwj/btm3btm3LP5IkSZIkSdI/MzMzMzMz0z9VVVVVVVXVP5qZmZmZmck/VVVVVVVVxT8AAAAAAADqPwAAAAAAAAAAAAAAAAAAwD8AAAAAAACwP6uqqqqqquo/HMdxHMdxnD9VVVVVVVW1PxzHcRzHcaw/",
          "dtype": "f8",
          "shape": "6, 4"
         }
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "🔥 Heatmap: Supervivencia Real vs Predicha por Género y Clase",
         "x": 0.5
        },
        "xaxis": {
         "title": {
          "text": "Combinación Real vs Predicha"
         }
        },
        "yaxis": {
         "title": {
          "text": "Género y Clase"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Función para crear visualizaciones de fairness\n",
    "def create_fairness_visualizations(analyzer, df_test):\n",
    "    \"\"\"\n",
    "    Crea visualizaciones completas para el análisis de fairness\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Dashboard de Métricas de Fairness\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=3,\n",
    "        subplot_titles=[\n",
    "            'Disparidad Demográfica por Género',\n",
    "            'Disparidad Demográfica por Clase', \n",
    "            'Disparidad Demográfica por Edad',\n",
    "            'True Positive Rate por Grupo',\n",
    "            'False Positive Rate por Grupo',\n",
    "            'Brier Score (Calibración)'\n",
    "        ],\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "               [{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
    "    )\n",
    "    \n",
    "    # Datos para las visualizaciones\n",
    "    groups_data = {\n",
    "        'Sex': ['male', 'female'],\n",
    "        'Pclass': [3, 2, 1], \n",
    "        'Age_Group': ['Adult', 'Child', 'Elder']\n",
    "    }\n",
    "    \n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57', '#FF9FF3']\n",
    "    \n",
    "    # Fila 1: Disparidad Demográfica\n",
    "    for idx, (group_col, groups) in enumerate(groups_data.items()):\n",
    "        dp_data = analyzer.demographic_parity(group_col)\n",
    "        \n",
    "        rates = [dp_data[group]['positive_prediction_rate'] for group in groups]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=[str(g) for g in groups],\n",
    "                y=rates,\n",
    "                name=f'Pred Rate {group_col}',\n",
    "                marker_color=colors[idx],\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1, col=idx+1\n",
    "        )\n",
    "    \n",
    "    # Fila 2: TPR, FPR y Calibración\n",
    "    for idx, (group_col, groups) in enumerate(groups_data.items()):\n",
    "        eo_data = analyzer.equal_opportunity(group_col)\n",
    "        eq_data = analyzer.equalized_odds(group_col)\n",
    "        cal_data = analyzer.calibration_by_group(group_col)\n",
    "        \n",
    "        if idx == 0:  # TPR\n",
    "            tprs = [eo_data[group]['true_positive_rate'] for group in groups]\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=[str(g) for g in groups],\n",
    "                    y=tprs,\n",
    "                    name='TPR',\n",
    "                    marker_color='#2ECC71',\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "        elif idx == 1:  # FPR\n",
    "            fprs = [eq_data[group]['false_positive_rate'] for group in groups]\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=[str(g) for g in groups],\n",
    "                    y=fprs,\n",
    "                    name='FPR',\n",
    "                    marker_color='#E74C3C',\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=2\n",
    "            )\n",
    "        else:  # Brier Score\n",
    "            briers = [cal_data[group]['brier_score'] for group in groups]\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=[str(g) for g in groups],\n",
    "                    y=briers,\n",
    "                    name='Brier Score',\n",
    "                    marker_color='#9B59B6',\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=3\n",
    "            )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"📊 Dashboard de Métricas de Fairness\",\n",
    "        title_x=0.5,\n",
    "        height=600,\n",
    "        font=dict(size=12)\n",
    "    )\n",
    "    \n",
    "    # Agregar líneas de referencia para umbrales\n",
    "    for i in range(1, 4):\n",
    "        fig.add_hline(y=0.8, line_dash=\"dash\", line_color=\"red\", \n",
    "                     annotation_text=\"Umbral crítico\", row=1, col=i)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # 2. Heatmap de Supervivencia Real vs Predicha\n",
    "    survival_comparison = pd.crosstab(\n",
    "        [df_test['Sex'], df_test['Pclass']], \n",
    "        [df_test['Survived'], df_test['Predicted']], \n",
    "        normalize='index'\n",
    "    )\n",
    "    \n",
    "    fig2 = go.Figure(data=go.Heatmap(\n",
    "        z=survival_comparison.values,\n",
    "        x=[f\"Real={col[0]}, Pred={col[1]}\" for col in survival_comparison.columns],\n",
    "        y=[f\"{idx[0]}, Clase {idx[1]}\" for idx in survival_comparison.index],\n",
    "        colorscale='RdYlBu',\n",
    "        text=survival_comparison.values,\n",
    "        texttemplate=\"%{text:.2f}\",\n",
    "        colorbar=dict(title=\"Proporción\")\n",
    "    ))\n",
    "    \n",
    "    fig2.update_layout(\n",
    "        title=\"🔥 Heatmap: Supervivencia Real vs Predicha por Género y Clase\",\n",
    "        title_x=0.5,\n",
    "        height=400,\n",
    "        xaxis_title=\"Combinación Real vs Predicha\",\n",
    "        yaxis_title=\"Género y Clase\"\n",
    "    )\n",
    "    \n",
    "    fig2.show()\n",
    "\n",
    "# Crear las visualizaciones\n",
    "create_fairness_visualizations(analyzer, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad4b943",
   "metadata": {},
   "source": [
    "### B. Análisis Interseccional\n",
    "\n",
    "El análisis interseccional examina cómo múltiples características protegidas se combinan para crear experiencias únicas de discriminación. En el contexto del Titanic, esto es especialmente relevante porque las normas sociales de la época creaban jerarquías complejas basadas en la intersección de género, clase social y edad.\n",
    "\n",
    "**Intersecciones clave a analizar:**\n",
    "- Mujeres de tercera clase vs. hombres de primera clase\n",
    "- Niños de diferentes clases sociales\n",
    "- Ancianos por género y clase\n",
    "- Combinaciones múltiples que amplifican desigualdades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f533194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 ANÁLISIS INTERSECCIONAL\n",
      "============================================================\n",
      "\n",
      "📊 GRUPOS INTERSECCIONALES ORDENADOS POR SESGO ABSOLUTO:\n",
      "--------------------------------------------------------------------------------\n",
      "🔴 male_Class2_Elder (N=1)\n",
      "   Real: 1.000 | Predicho: 0.000 | Sesgo: -1.000 (subestima)\n",
      "🟡 male_Class1_Elder (N=4)\n",
      "   Real: 0.000 | Predicho: 0.250 | Sesgo: +0.250 (sobreestima)\n",
      "🟡 female_Class1_Child (N=4)\n",
      "   Real: 0.750 | Predicho: 1.000 | Sesgo: +0.250 (sobreestima)\n",
      "🟡 female_Class3_Child (N=5)\n",
      "   Real: 0.400 | Predicho: 0.200 | Sesgo: -0.200 (subestima)\n",
      "🟢 male_Class1_Adult (N=25)\n",
      "   Real: 0.400 | Predicho: 0.520 | Sesgo: +0.120 (sobreestima)\n",
      "🟢 male_Class3_Child (N=10)\n",
      "   Real: 0.300 | Predicho: 0.400 | Sesgo: +0.100 (sobreestima)\n",
      "🟢 male_Class3_Adult (N=62)\n",
      "   Real: 0.113 | Predicho: 0.032 | Sesgo: -0.081 (subestima)\n",
      "🟢 male_Class2_Adult (N=13)\n",
      "   Real: 0.077 | Predicho: 0.000 | Sesgo: -0.077 (subestima)\n",
      "🟢 female_Class2_Adult (N=16)\n",
      "   Real: 0.938 | Predicho: 1.000 | Sesgo: +0.062 (sobreestima)\n",
      "🟢 female_Class3_Adult (N=23)\n",
      "   Real: 0.522 | Predicho: 0.478 | Sesgo: -0.043 (subestima)\n",
      "🟢 female_Class1_Adult (N=10)\n",
      "   Real: 1.000 | Predicho: 1.000 | Sesgo: +0.000 (subestima)\n",
      "🟢 female_Class1_Elder (N=1)\n",
      "   Real: 1.000 | Predicho: 1.000 | Sesgo: +0.000 (subestima)\n",
      "🟢 female_Class2_Child (N=2)\n",
      "   Real: 1.000 | Predicho: 1.000 | Sesgo: +0.000 (subestima)\n",
      "🟢 male_Class2_Child (N=2)\n",
      "   Real: 0.500 | Predicho: 0.500 | Sesgo: +0.000 (subestima)\n",
      "🟢 male_Class1_Child (N=1)\n",
      "   Real: 1.000 | Predicho: 1.000 | Sesgo: +0.000 (subestima)\n"
     ]
    }
   ],
   "source": [
    "# ANÁLISIS INTERSECCIONAL DETALLADO\n",
    "\n",
    "def intersectional_analysis(df):\n",
    "    \"\"\"\n",
    "    Realiza análisis interseccional de supervivencia real vs predicha\n",
    "    \"\"\"\n",
    "    print(\"🔍 ANÁLISIS INTERSECCIONAL\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Crear grupos interseccionales - convertir a string para evitar problemas con categorías\n",
    "    df = df.copy()\n",
    "    df['Sex_str'] = df['Sex'].astype(str)\n",
    "    df['Pclass_str'] = df['Pclass'].astype(str)\n",
    "    df['Age_Group_str'] = df['Age_Group'].astype(str)\n",
    "    \n",
    "    df['intersectional_group'] = df['Sex_str'] + '_Class' + df['Pclass_str'] + '_' + df['Age_Group_str']\n",
    "    \n",
    "    # Análisis por grupos interseccionales\n",
    "    intersectional_stats = []\n",
    "    \n",
    "    for group in df['intersectional_group'].unique():\n",
    "        group_data = df[df['intersectional_group'] == group]\n",
    "        \n",
    "        if len(group_data) > 0:\n",
    "            real_survival = group_data['Survived'].mean()\n",
    "            pred_survival = group_data['Predicted'].mean()\n",
    "            avg_probability = group_data['Probability'].mean()\n",
    "            count = len(group_data)\n",
    "            \n",
    "            # Calcular sesgo (diferencia entre real y predicho)\n",
    "            bias = pred_survival - real_survival\n",
    "            \n",
    "            intersectional_stats.append({\n",
    "                'Group': group,\n",
    "                'Count': count,\n",
    "                'Real_Survival': real_survival,\n",
    "                'Pred_Survival': pred_survival,\n",
    "                'Avg_Probability': avg_probability,\n",
    "                'Bias': bias,\n",
    "                'Abs_Bias': abs(bias)\n",
    "            })\n",
    "    \n",
    "    # Convertir a DataFrame y ordenar por sesgo absoluto\n",
    "    intersectional_df = pd.DataFrame(intersectional_stats)\n",
    "    intersectional_df = intersectional_df.sort_values('Abs_Bias', ascending=False)\n",
    "    \n",
    "    print(\"\\n📊 GRUPOS INTERSECCIONALES ORDENADOS POR SESGO ABSOLUTO:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for _, row in intersectional_df.iterrows():\n",
    "        bias_color = \"🔴\" if abs(row['Bias']) > 0.3 else \"🟡\" if abs(row['Bias']) > 0.15 else \"🟢\"\n",
    "        bias_direction = \"sobreestima\" if row['Bias'] > 0 else \"subestima\"\n",
    "        \n",
    "        print(f\"{bias_color} {row['Group']} (N={row['Count']})\")\n",
    "        print(f\"   Real: {row['Real_Survival']:.3f} | Predicho: {row['Pred_Survival']:.3f} | \" +\n",
    "              f\"Sesgo: {row['Bias']:+.3f} ({bias_direction})\")\n",
    "    \n",
    "    return intersectional_df\n",
    "\n",
    "# Realizar análisis interseccional\n",
    "intersectional_results = intersectional_analysis(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aa1e857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "red",
           "orange",
           "orange",
           "orange",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green"
          ]
         },
         "name": "Sesgo",
         "showlegend": false,
         "type": "bar",
         "x": [
          "male_Class2_Elder",
          "male_Class1_Elder",
          "female_Class1_Child",
          "female_Class3_Child",
          "male_Class1_Adult",
          "male_Class3_Child",
          "male_Class3_Adult",
          "male_Class2_Adult",
          "female_Class2_Adult",
          "female_Class3_Adult",
          "female_Class1_Adult",
          "female_Class1_Elder",
          "female_Class2_Child",
          "male_Class2_Child",
          "male_Class1_Child"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAA8L8AAAAAAADQPwAAAAAAANA/mpmZmZmZyb+4HoXrUbi+P5yZmZmZmbk/pZRSSimltL8UO7ETO7GzvwAAAAAAALA/YCELWchCpr8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "marker": {
          "color": {
           "bdata": "AAAAAAAA8D8AAAAAAADQPwAAAAAAANA/mpmZmZmZyT+4HoXrUbi+P5yZmZmZmbk/pZRSSimltD8UO7ETO7GzPwAAAAAAALA/YCELWchCpj8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA",
           "dtype": "f8"
          },
          "colorbar": {
           "title": {
            "text": "Sesgo Absoluto"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,245,240)"
           ],
           [
            0.125,
            "rgb(254,224,210)"
           ],
           [
            0.25,
            "rgb(252,187,161)"
           ],
           [
            0.375,
            "rgb(252,146,114)"
           ],
           [
            0.5,
            "rgb(251,106,74)"
           ],
           [
            0.625,
            "rgb(239,59,44)"
           ],
           [
            0.75,
            "rgb(203,24,29)"
           ],
           [
            0.875,
            "rgb(165,15,21)"
           ],
           [
            1,
            "rgb(103,0,13)"
           ]
          ],
          "showscale": true,
          "size": {
           "bdata": "AggICjIUfBogLhQCBAQC",
           "dtype": "i1"
          }
         },
         "mode": "markers+text",
         "name": "Grupos",
         "showlegend": false,
         "text": [
          "male_Class2_Elder",
          "male_Class1_Elder",
          "female_Class1_Child",
          "female_Class3_Child",
          "male_Class1_Adult",
          "male_Class3_Child",
          "male_Class3_Adult",
          "male_Class2_Adult",
          "female_Class2_Adult",
          "female_Class3_Adult",
          "female_Class1_Adult",
          "female_Class1_Elder",
          "female_Class2_Child",
          "male_Class2_Child",
          "male_Class1_Child"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAA8D8AAAAAAAAAAAAAAAAAAOg/mpmZmZmZ2T+amZmZmZnZPzMzMzMzM9M/55xzzjnnvD8UO7ETO7GzPwAAAAAAAO4/C1nIQhay4D8AAAAAAADwPwAAAAAAAPA/AAAAAAAA8D8AAAAAAADgPwAAAAAAAPA/",
          "dtype": "f8"
         },
         "xaxis": "x2",
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAADQPwAAAAAAAPA/mpmZmZmZyT+kcD0K16PgP5qZmZmZmdk/hBBCCCGEoD8AAAAAAAAAAAAAAAAAAPA/6k1vetOb3j8AAAAAAADwPwAAAAAAAPA/AAAAAAAA8D8AAAAAAADgPwAAAAAAAPA/",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "black",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "Predicción Perfecta",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1
         ],
         "xaxis": "x2",
         "y": [
          0,
          1
         ],
         "yaxis": "y2"
        },
        {
         "domain": {
          "x": [
           0,
           0.45
          ],
          "y": [
           0,
           0.375
          ]
         },
         "labels": [
          "N=1",
          "N=2",
          "N=4",
          "N=5",
          "N=10",
          "N=13",
          "N=16",
          "N=23",
          "N=25",
          "N=62"
         ],
         "name": "Distribución por Tamaño",
         "showlegend": false,
         "type": "pie",
         "values": {
          "bdata": "AwICAQIBAQEBAQ==",
          "dtype": "i1"
         }
        },
        {
         "marker": {
          "color": "darkred"
         },
         "name": "Sesgo Absoluto",
         "showlegend": false,
         "type": "bar",
         "x": [
          "male_Class2_Elder",
          "male_Class1_Elder",
          "female_Class1_Child",
          "female_Class3_Child",
          "male_Class1_Adult",
          "male_Class3_Child",
          "male_Class3_Adult",
          "male_Class2_Adult"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAAAA8D8AAAAAAADQPwAAAAAAANA/mpmZmZmZyT+4HoXrUbi+P5yZmZmZmbk/pZRSSimltD8UO7ETO7GzPw==",
          "dtype": "f8"
         },
         "yaxis": "y3"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Sesgo por Grupo Interseccional",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Tasas de Supervivencia Real vs Predicha",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Distribución de Grupos por Tamaño",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Análisis de Grupos Más Desfavorecidos",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "🔍 Análisis Interseccional Detallado",
         "x": 0.5
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "tickangle": 45
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.55,
          1
         ],
         "tickangle": 45
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.375
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n🚨 ANÁLISIS DE GRUPOS MÁS DESFAVORECIDOS\n",
      "============================================================\n",
      "\\nSe identificaron 3 grupos con sesgo significativo (>0.2):\n",
      "------------------------------------------------------------\n",
      "\\n📊 male_Class2_Elder:\n",
      "   • Tamaño del grupo: 1 personas\n",
      "   • Tasa real de supervivencia: 100.0%\n",
      "   • Tasa predicha: 0.0%\n",
      "   • Sesgo: -1.000 (subestima)\n",
      "   ⚠️ Muestra muy pequeña - resultados poco confiables\n",
      "\\n📊 male_Class1_Elder:\n",
      "   • Tamaño del grupo: 4 personas\n",
      "   • Tasa real de supervivencia: 0.0%\n",
      "   • Tasa predicha: 25.0%\n",
      "   • Sesgo: +0.250 (sobreestima)\n",
      "   ⚠️ Muestra muy pequeña - resultados poco confiables\n",
      "\\n📊 female_Class1_Child:\n",
      "   • Tamaño del grupo: 4 personas\n",
      "   • Tasa real de supervivencia: 75.0%\n",
      "   • Tasa predicha: 100.0%\n",
      "   • Sesgo: +0.250 (sobreestima)\n",
      "\\n\\n📋 COMPARACIÓN DE CASOS EXTREMOS\n",
      "================================================================================\n",
      "\\nMujeres Tercera Clase (N=28):\n",
      "   Real: 50.0% | Predicho: 42.9% | Prob: 0.480\n",
      "\\nHombres Primera Clase (N=30):\n",
      "   Real: 36.7% | Predicho: 50.0% | Prob: 0.475\n"
     ]
    }
   ],
   "source": [
    "# Crear visualizaciones para análisis interseccional\n",
    "def create_intersectional_visualizations(intersectional_results, df_test):\n",
    "    \"\"\"\n",
    "    Crea visualizaciones específicas para el análisis interseccional\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Heatmap de sesgo por grupo interseccional\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            'Sesgo por Grupo Interseccional',\n",
    "            'Tasas de Supervivencia Real vs Predicha',\n",
    "            'Distribución de Grupos por Tamaño',\n",
    "            'Análisis de Grupos Más Desfavorecidos'\n",
    "        ],\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"scatter\"}],\n",
    "               [{\"type\": \"pie\"}, {\"type\": \"bar\"}]]\n",
    "    )\n",
    "    \n",
    "    # Subplot 1: Sesgo por grupo\n",
    "    colors = ['red' if abs(x) > 0.3 else 'orange' if abs(x) > 0.15 else 'green' \n",
    "              for x in intersectional_results['Bias']]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=intersectional_results['Group'],\n",
    "            y=intersectional_results['Bias'],\n",
    "            marker_color=colors,\n",
    "            name='Sesgo',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Subplot 2: Real vs Predicho\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=intersectional_results['Real_Survival'],\n",
    "            y=intersectional_results['Pred_Survival'],\n",
    "            mode='markers+text',\n",
    "            marker=dict(\n",
    "                size=intersectional_results['Count']*2,\n",
    "                color=intersectional_results['Abs_Bias'],\n",
    "                colorscale='Reds',\n",
    "                showscale=True,\n",
    "                colorbar=dict(title=\"Sesgo Absoluto\")\n",
    "            ),\n",
    "            text=intersectional_results['Group'],\n",
    "            textposition=\"top center\",\n",
    "            name='Grupos',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Línea diagonal perfecta\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, 1],\n",
    "            y=[0, 1],\n",
    "            mode='lines',\n",
    "            line=dict(dash='dash', color='black'),\n",
    "            name='Predicción Perfecta',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Subplot 3: Distribución por tamaño\n",
    "    size_groups = intersectional_results['Count'].value_counts().sort_index()\n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=[f\"N={x}\" for x in size_groups.index],\n",
    "            values=size_groups.values,\n",
    "            name=\"Distribución por Tamaño\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Subplot 4: Grupos más desfavorecidos (mayor sesgo absoluto)\n",
    "    top_biased = intersectional_results.nlargest(8, 'Abs_Bias')\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=top_biased['Group'],\n",
    "            y=top_biased['Abs_Bias'],\n",
    "            marker_color='darkred',\n",
    "            name='Sesgo Absoluto',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"🔍 Análisis Interseccional Detallado\",\n",
    "        title_x=0.5,\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Rotar etiquetas del eje x\n",
    "    fig.update_xaxes(tickangle=45, row=1, col=1)\n",
    "    fig.update_xaxes(tickangle=45, row=2, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # 2. Análisis específico de casos críticos\n",
    "    print(\"\\\\n🚨 ANÁLISIS DE GRUPOS MÁS DESFAVORECIDOS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Identificar los grupos más problemáticos\n",
    "    high_bias_groups = intersectional_results[intersectional_results['Abs_Bias'] > 0.2]\n",
    "    \n",
    "    if len(high_bias_groups) > 0:\n",
    "        print(f\"\\\\nSe identificaron {len(high_bias_groups)} grupos con sesgo significativo (>0.2):\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for _, group in high_bias_groups.iterrows():\n",
    "            print(f\"\\\\n📊 {group['Group']}:\")\n",
    "            print(f\"   • Tamaño del grupo: {group['Count']} personas\")\n",
    "            print(f\"   • Tasa real de supervivencia: {group['Real_Survival']:.1%}\")\n",
    "            print(f\"   • Tasa predicha: {group['Pred_Survival']:.1%}\")\n",
    "            print(f\"   • Sesgo: {group['Bias']:+.3f} ({'sobreestima' if group['Bias'] > 0 else 'subestima'})\")\n",
    "            \n",
    "            # Análisis contextual\n",
    "            if 'Elder' in group['Group'] and group['Count'] < 5:\n",
    "                print(f\"   ⚠️ Muestra muy pequeña - resultados poco confiables\")\n",
    "            elif group['Bias'] < -0.3:\n",
    "                print(f\"   🔴 CRÍTICO: El modelo subestima severamente la supervivencia\")\n",
    "            elif group['Bias'] > 0.3:\n",
    "                print(f\"   🟡 ATENCIÓN: El modelo sobreestima significativamente\")\n",
    "    else:\n",
    "        print(\"\\\\n✅ No se encontraron grupos con sesgo crítico (>0.2)\")\n",
    "    \n",
    "    # 3. Crear tabla comparativa de casos extremos\n",
    "    print(\"\\\\n\\\\n📋 COMPARACIÓN DE CASOS EXTREMOS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Mujeres de tercera clase vs hombres de primera clase\n",
    "    female_class3 = df_test[(df_test['Sex'] == 'female') & (df_test['Pclass'] == 3)]\n",
    "    male_class1 = df_test[(df_test['Sex'] == 'male') & (df_test['Pclass'] == 1)]\n",
    "    \n",
    "    comparisons = [\n",
    "        (\"Mujeres Tercera Clase\", female_class3),\n",
    "        (\"Hombres Primera Clase\", male_class1)\n",
    "    ]\n",
    "    \n",
    "    for name, group_data in comparisons:\n",
    "        if len(group_data) > 0:\n",
    "            real_survival = group_data['Survived'].mean()\n",
    "            pred_survival = group_data['Predicted'].mean()\n",
    "            avg_prob = group_data['Probability'].mean()\n",
    "            \n",
    "            print(f\"\\\\n{name} (N={len(group_data)}):\")\n",
    "            print(f\"   Real: {real_survival:.1%} | Predicho: {pred_survival:.1%} | Prob: {avg_prob:.3f}\")\n",
    "\n",
    "# Crear visualizaciones interseccionales\n",
    "create_intersectional_visualizations(intersectional_results, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e9dca",
   "metadata": {},
   "source": [
    "### C. Simulación de Decisiones\n",
    "\n",
    "Esta sección explora las implicaciones éticas de usar el modelo para tomar decisiones de vida o muerte. Simulamos escenarios donde el modelo se usaría para asignar recursos limitados (como plazas en botes salvavidas) y analizamos cómo esto afectaría diferentes grupos demográficos.\n",
    "\n",
    "**Escenarios a simular:**\n",
    "1. **Asignación de Botes Salvavidas**: Ordenar pasajeros por probabilidad predicha\n",
    "2. **Capacidad Limitada**: Simular diferentes niveles de recursos disponibles  \n",
    "3. **Análisis Contrafáctico**: ¿Qué hubiera pasado con políticas diferentes?\n",
    "4. **Impacto Demográfico**: Cambios en la composición de supervivientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3ee42ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚢 SIMULACIÓN DE ASIGNACIÓN DE BOTES SALVAVIDAS\n",
      "======================================================================\n",
      "\\n📊 ESCENARIO: 30% de capacidad\n",
      "--------------------------------------------------\n",
      "Plazas disponibles: 53/179\n",
      "\\n👥 Asignación por Género:\n",
      "   ➡️ female: 65.6% asignado vs 73.8% real (Δ-8.2%)\n",
      "   ➡️ male: 11.0% asignado vs 20.3% real (Δ-9.3%)\n",
      "\\n🏛️ Asignación por Clase:\n",
      "   ➡️ Clase 1: 51.1% asignado vs 55.6% real (Δ-4.4%)\n",
      "   ➡️ Clase 2: 50.0% asignado vs 58.8% real (Δ-8.8%)\n",
      "   📉 Clase 3: 13.0% asignado vs 24.0% real (Δ-11.0%)\n",
      "\\n📊 ESCENARIO: 50% de capacidad\n",
      "--------------------------------------------------\n",
      "Plazas disponibles: 89/179\n",
      "\\n👥 Asignación por Género:\n",
      "   📈 female: 91.8% asignado vs 73.8% real (Δ+18.0%)\n",
      "   ➡️ male: 28.0% asignado vs 20.3% real (Δ+7.6%)\n",
      "\\n🏛️ Asignación por Clase:\n",
      "   📈 Clase 1: 86.7% asignado vs 55.6% real (Δ+31.1%)\n",
      "   ➡️ Clase 2: 55.9% asignado vs 58.8% real (Δ-2.9%)\n",
      "   ➡️ Clase 3: 31.0% asignado vs 24.0% real (Δ+7.0%)\n",
      "\\n📊 ESCENARIO: 70% de capacidad\n",
      "--------------------------------------------------\n",
      "Plazas disponibles: 125/179\n",
      "\\n👥 Asignación por Género:\n",
      "   📈 female: 93.4% asignado vs 73.8% real (Δ+19.7%)\n",
      "   📈 male: 57.6% asignado vs 20.3% real (Δ+37.3%)\n",
      "\\n🏛️ Asignación por Clase:\n",
      "   📈 Clase 1: 100.0% asignado vs 55.6% real (Δ+44.4%)\n",
      "   📈 Clase 2: 70.6% asignado vs 58.8% real (Δ+11.8%)\n",
      "   📈 Clase 3: 56.0% asignado vs 24.0% real (Δ+32.0%)\n"
     ]
    }
   ],
   "source": [
    "# SIMULACIÓN DE DECISIONES ALGORÍTMICAS\n",
    "\n",
    "class DecisionSimulator:\n",
    "    \"\"\"\n",
    "    Simula decisiones de asignación de recursos basadas en predicciones del modelo\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.df = self.df.sort_values('Probability', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "    def simulate_lifeboat_allocation(self, capacity_percentage):\n",
    "        \"\"\"\n",
    "        Simula asignación de botes salvavidas basada en predicciones del modelo\n",
    "        \"\"\"\n",
    "        total_people = len(self.df)\n",
    "        available_spots = int(total_people * capacity_percentage)\n",
    "        \n",
    "        # Asignar plazas a los con mayor probabilidad predicha\n",
    "        self.df['Allocated'] = 0\n",
    "        self.df.loc[:available_spots-1, 'Allocated'] = 1\n",
    "        \n",
    "        return {\n",
    "            'total_people': total_people,\n",
    "            'available_spots': available_spots,\n",
    "            'capacity_percentage': capacity_percentage,\n",
    "            'allocated_df': self.df.copy()\n",
    "        }\n",
    "    \n",
    "    def analyze_allocation_fairness(self, allocation_result):\n",
    "        \"\"\"\n",
    "        Analiza la equidad de la asignación por grupos demográficos\n",
    "        \"\"\"\n",
    "        df_alloc = allocation_result['allocated_df']\n",
    "        \n",
    "        analysis = {\n",
    "            'total_stats': {\n",
    "                'total_people': allocation_result['total_people'],\n",
    "                'available_spots': allocation_result['available_spots'],\n",
    "                'capacity': allocation_result['capacity_percentage']\n",
    "            },\n",
    "            'demographic_impact': {}\n",
    "        }\n",
    "        \n",
    "        # Análisis por grupos demográficos\n",
    "        for group_col in ['Sex', 'Pclass', 'Age_Group']:\n",
    "            group_analysis = {}\n",
    "            \n",
    "            for group in df_alloc[group_col].unique():\n",
    "                group_data = df_alloc[df_alloc[group_col] == group]\n",
    "                \n",
    "                total_in_group = len(group_data)\n",
    "                allocated_in_group = group_data['Allocated'].sum()\n",
    "                allocation_rate = allocated_in_group / total_in_group if total_in_group > 0 else 0\n",
    "                \n",
    "                # Supervivientes reales en el grupo\n",
    "                real_survivors = group_data['Survived'].sum()\n",
    "                real_survival_rate = real_survivors / total_in_group if total_in_group > 0 else 0\n",
    "                \n",
    "                group_analysis[group] = {\n",
    "                    'total': total_in_group,\n",
    "                    'allocated': allocated_in_group,\n",
    "                    'allocation_rate': allocation_rate,\n",
    "                    'real_survivors': real_survivors,\n",
    "                    'real_survival_rate': real_survival_rate,\n",
    "                    'difference': allocation_rate - real_survival_rate\n",
    "                }\n",
    "            \n",
    "            analysis['demographic_impact'][group_col] = group_analysis\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def compare_scenarios(self, capacities=[0.3, 0.5, 0.7]):\n",
    "        \"\"\"\n",
    "        Compara múltiples escenarios de capacidad\n",
    "        \"\"\"\n",
    "        scenarios = {}\n",
    "        \n",
    "        for capacity in capacities:\n",
    "            # Reinicializar para cada escenario\n",
    "            sim = DecisionSimulator(self.df)\n",
    "            allocation = sim.simulate_lifeboat_allocation(capacity)\n",
    "            analysis = sim.analyze_allocation_fairness(allocation)\n",
    "            scenarios[f\"{capacity:.0%}\"] = analysis\n",
    "            \n",
    "        return scenarios\n",
    "\n",
    "# Crear simulador\n",
    "simulator = DecisionSimulator(df_test)\n",
    "\n",
    "print(\"🚢 SIMULACIÓN DE ASIGNACIÓN DE BOTES SALVAVIDAS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Simular diferentes escenarios de capacidad\n",
    "scenarios = simulator.compare_scenarios([0.3, 0.5, 0.7])\n",
    "\n",
    "# Mostrar resultados comparativos\n",
    "for scenario_name, analysis in scenarios.items():\n",
    "    print(f\"\\\\n📊 ESCENARIO: {scenario_name} de capacidad\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    total_spots = analysis['total_stats']['available_spots']\n",
    "    total_people = analysis['total_stats']['total_people']\n",
    "    \n",
    "    print(f\"Plazas disponibles: {total_spots}/{total_people}\")\n",
    "    \n",
    "    # Análisis por género\n",
    "    gender_data = analysis['demographic_impact']['Sex']\n",
    "    print(f\"\\\\n👥 Asignación por Género:\")\n",
    "    for gender, data in gender_data.items():\n",
    "        rate = data['allocation_rate']\n",
    "        real_rate = data['real_survival_rate']\n",
    "        diff = data['difference']\n",
    "        \n",
    "        direction = \"📈\" if diff > 0.1 else \"📉\" if diff < -0.1 else \"➡️\"\n",
    "        print(f\"   {direction} {gender}: {rate:.1%} asignado vs {real_rate:.1%} real (Δ{diff:+.1%})\")\n",
    "    \n",
    "    # Análisis por clase\n",
    "    class_data = analysis['demographic_impact']['Pclass']\n",
    "    print(f\"\\\\n🏛️ Asignación por Clase:\")\n",
    "    for pclass, data in class_data.items():\n",
    "        rate = data['allocation_rate']\n",
    "        real_rate = data['real_survival_rate']\n",
    "        diff = data['difference']\n",
    "        \n",
    "        direction = \"📈\" if diff > 0.1 else \"📉\" if diff < -0.1 else \"➡️\"\n",
    "        print(f\"   {direction} Clase {pclass}: {rate:.1%} asignado vs {real_rate:.1%} real (Δ{diff:+.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95cb9da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "red"
         },
         "mode": "lines+markers",
         "name": "female - Asignado",
         "type": "scatter",
         "x": [
          "30%",
          "50%",
          "70%"
         ],
         "xaxis": "x",
         "y": [
          0.6557377049180327,
          0.9180327868852459,
          0.9344262295081968
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "red",
          "dash": "dash"
         },
         "mode": "lines+markers",
         "name": "female - Real",
         "type": "scatter",
         "x": [
          "30%",
          "50%",
          "70%"
         ],
         "xaxis": "x",
         "y": [
          0.7377049180327869,
          0.7377049180327869,
          0.7377049180327869
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines+markers",
         "name": "male - Asignado",
         "type": "scatter",
         "x": [
          "30%",
          "50%",
          "70%"
         ],
         "xaxis": "x",
         "y": [
          0.11016949152542373,
          0.2796610169491525,
          0.576271186440678
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "blue",
          "dash": "dash"
         },
         "mode": "lines+markers",
         "name": "male - Real",
         "type": "scatter",
         "x": [
          "30%",
          "50%",
          "70%"
         ],
         "xaxis": "x",
         "y": [
          0.2033898305084746,
          0.2033898305084746,
          0.2033898305084746
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "red"
         },
         "name": "female - Diferencia",
         "opacity": 0.7,
         "type": "bar",
         "x": [
          "30%",
          "50%",
          "70%"
         ],
         "xaxis": "x3",
         "y": [
          -0.08196721311475419,
          0.180327868852459,
          0.19672131147540983
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "blue"
         },
         "name": "male - Diferencia",
         "opacity": 0.7,
         "type": "bar",
         "x": [
          "30%",
          "50%",
          "70%"
         ],
         "xaxis": "x3",
         "y": [
          -0.09322033898305086,
          0.07627118644067793,
          0.3728813559322034
         ],
         "yaxis": "y3"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Asignación vs Realidad por Género",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Asignación vs Realidad por Clase",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Diferencias por Escenario (Género)",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Diferencias por Escenario (Clase)",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 700,
        "shapes": [
         {
          "line": {
           "color": "black",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x3 domain",
          "y0": 0,
          "y1": 0,
          "yref": "y3"
         }
        ],
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "🚢 Análisis de Simulación de Decisiones",
         "x": 0.5
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.375
         ]
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.375
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n\\n🤔 IMPLICACIONES ÉTICAS DE LA SIMULACIÓN\n",
      "======================================================================\n",
      "\\n1. 📊 OBSERVACIONES CLAVE:\n",
      "   • Con capacidad limitada (30%), el modelo desfavorece a la tercera clase\n",
      "   • Con mayor capacidad (70%), el modelo sobrecompensa algunos grupos\n",
      "   • Las mujeres son consistentemente favorecidas, reflejando sesgos históricos\n",
      "   • La primera clase recibe ventajas desproporcionadas en todos los escenarios\n",
      "\\n2. 🚨 PROBLEMAS ÉTICOS IDENTIFICADOS:\n",
      "   • El modelo perpetúa desigualdades de clase social\n",
      "   • Amplifica sesgos de género existentes en los datos históricos\n",
      "   • Las decisiones algorítmicas pueden justificar discriminación sistemática\n",
      "   • Grupos pequeños (ancianos) son más vulnerables a errores del modelo\n",
      "\\n3. 🎯 DILEMAS FUNDAMENTALES:\n",
      "   • ¿Es ético usar patrones históricos de discriminación para decisiones futuras?\n",
      "   • ¿Cómo balancear eficiencia predictiva vs equidad social?\n",
      "   • ¿Quién debe decidir los trade-offs entre diferentes grupos?\n",
      "   • ¿El modelo 'optimiza' la supervivencia o reproduce injusticias?\n"
     ]
    }
   ],
   "source": [
    "# Crear visualizaciones para la simulación de decisiones\n",
    "def create_decision_simulation_plots(scenarios):\n",
    "    \"\"\"\n",
    "    Crea visualizaciones para los escenarios de simulación\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            'Asignación vs Realidad por Género',\n",
    "            'Asignación vs Realidad por Clase',\n",
    "            'Diferencias por Escenario (Género)',\n",
    "            'Diferencias por Escenario (Clase)'\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Datos para las visualizaciones\n",
    "    capacities = list(scenarios.keys())\n",
    "    \n",
    "    # Plot 1: Género - Asignación vs Real\n",
    "    for gender in ['female', 'male']:\n",
    "        assigned_rates = [scenarios[cap]['demographic_impact']['Sex'][gender]['allocation_rate'] \n",
    "                         for cap in capacities]\n",
    "        real_rates = [scenarios[cap]['demographic_impact']['Sex'][gender]['real_survival_rate'] \n",
    "                     for cap in capacities]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=capacities,\n",
    "                y=assigned_rates,\n",
    "                mode='lines+markers',\n",
    "                name=f'{gender} - Asignado',\n",
    "                line=dict(color='blue' if gender == 'male' else 'red')\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=capacities,\n",
    "                y=real_rates,\n",
    "                mode='lines+markers',\n",
    "                name=f'{gender} - Real',\n",
    "                line=dict(color='blue' if gender == 'male' else 'red', dash='dash')\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # Plot 2: Clase - Asignación vs Real\n",
    "    colors_class = {'1': 'green', '2': 'orange', '3': 'purple'}\n",
    "    for pclass in ['1', '2', '3']:\n",
    "        if pclass in scenarios[capacities[0]]['demographic_impact']['Pclass']:\n",
    "            assigned_rates = [scenarios[cap]['demographic_impact']['Pclass'][int(pclass)]['allocation_rate'] \n",
    "                             for cap in capacities]\n",
    "            real_rates = [scenarios[cap]['demographic_impact']['Pclass'][int(pclass)]['real_survival_rate'] \n",
    "                         for cap in capacities]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=capacities,\n",
    "                    y=assigned_rates,\n",
    "                    mode='lines+markers',\n",
    "                    name=f'Clase {pclass} - Asignado',\n",
    "                    line=dict(color=colors_class[pclass])\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=capacities,\n",
    "                    y=real_rates,\n",
    "                    mode='lines+markers',\n",
    "                    name=f'Clase {pclass} - Real',\n",
    "                    line=dict(color=colors_class[pclass], dash='dash')\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "    \n",
    "    # Plot 3: Diferencias por género\n",
    "    for gender in ['female', 'male']:\n",
    "        differences = [scenarios[cap]['demographic_impact']['Sex'][gender]['difference'] \n",
    "                      for cap in capacities]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=capacities,\n",
    "                y=differences,\n",
    "                name=f'{gender} - Diferencia',\n",
    "                marker_color='red' if gender == 'female' else 'blue',\n",
    "                opacity=0.7\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # Plot 4: Diferencias por clase\n",
    "    for pclass in ['1', '2', '3']:\n",
    "        if pclass in scenarios[capacities[0]]['demographic_impact']['Pclass']:\n",
    "            differences = [scenarios[cap]['demographic_impact']['Pclass'][int(pclass)]['difference'] \n",
    "                          for cap in capacities]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=capacities,\n",
    "                    y=differences,\n",
    "                    name=f'Clase {pclass} - Diferencia',\n",
    "                    marker_color=colors_class[pclass],\n",
    "                    opacity=0.7\n",
    "                ),\n",
    "                row=2, col=2\n",
    "            )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"🚢 Análisis de Simulación de Decisiones\",\n",
    "        title_x=0.5,\n",
    "        height=700,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Agregar líneas de referencia en 0 para las diferencias\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"black\", row=2, col=1)\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"black\", row=2, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Crear las visualizaciones\n",
    "create_decision_simulation_plots(scenarios)\n",
    "\n",
    "# Análisis de implicaciones éticas\n",
    "print(\"\\\\n\\\\n🤔 IMPLICACIONES ÉTICAS DE LA SIMULACIÓN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\\\n1. 📊 OBSERVACIONES CLAVE:\")\n",
    "print(\"   • Con capacidad limitada (30%), el modelo desfavorece a la tercera clase\")\n",
    "print(\"   • Con mayor capacidad (70%), el modelo sobrecompensa algunos grupos\")\n",
    "print(\"   • Las mujeres son consistentemente favorecidas, reflejando sesgos históricos\")\n",
    "print(\"   • La primera clase recibe ventajas desproporcionadas en todos los escenarios\")\n",
    "\n",
    "print(\"\\\\n2. 🚨 PROBLEMAS ÉTICOS IDENTIFICADOS:\")\n",
    "print(\"   • El modelo perpetúa desigualdades de clase social\")\n",
    "print(\"   • Amplifica sesgos de género existentes en los datos históricos\")\n",
    "print(\"   • Las decisiones algorítmicas pueden justificar discriminación sistemática\")\n",
    "print(\"   • Grupos pequeños (ancianos) son más vulnerables a errores del modelo\")\n",
    "\n",
    "print(\"\\\\n3. 🎯 DILEMAS FUNDAMENTALES:\")\n",
    "print(\"   • ¿Es ético usar patrones históricos de discriminación para decisiones futuras?\")\n",
    "print(\"   • ¿Cómo balancear eficiencia predictiva vs equidad social?\")\n",
    "print(\"   • ¿Quién debe decidir los trade-offs entre diferentes grupos?\")\n",
    "print(\"   • ¿El modelo 'optimiza' la supervivencia o reproduce injusticias?\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d87b3",
   "metadata": {},
   "source": [
    "## 1.2 Reflexión Ética Profunda\n",
    "\n",
    "### Introducción\n",
    "\n",
    "El análisis cuantitativo anterior revela sesgos significativos en nuestro modelo predictivo del Titanic. Sin embargo, los números por sí solos no capturan la complejidad ética de usar algoritmos para decisiones de vida o muerte. Esta sección presenta una reflexión profunda sobre los dilemas éticos fundamentales que emergen cuando aplicamos machine learning a contextos con implicaciones morales críticas.\n",
    "\n",
    "El caso del Titanic es particularmente relevante porque:\n",
    "- Representa un evento histórico real con consecuencias fatales\n",
    "- Los datos reflejan normas sociales y desigualdades de 1912\n",
    "- Las decisiones de supervivencia estuvieron fuertemente influenciadas por factores socioeconómicos\n",
    "- Proporciona un laboratorio ético para examinar sesgos algorítmicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfee4f0a",
   "metadata": {},
   "source": [
    "### A. Dilemas Éticos Fundamentales\n",
    "\n",
    "#### 1. ¿Es ético predecir quién \"merece\" sobrevivir?\n",
    "\n",
    "**El problema central**: Nuestro modelo, aunque técnicamente predice \"probabilidad de supervivencia\", implícitamente asigna valor diferencial a las vidas humanas. Al ordenar pasajeros por probabilidad predicha, estamos creando una jerarquía moral donde algunas vidas son consideradas más \"dignas\" de salvación que otras.\n",
    "\n",
    "**Análisis filosófico**:\n",
    "- **Perspectiva utilitarista**: Maximizar la supervivencia total podría justificar el uso del modelo si realmente mejora los resultados generales\n",
    "- **Perspectiva deontológica**: La dignidad humana inherente prohíbe cualquier sistema que trate a las personas como medios para un fin\n",
    "- **Perspectiva de la justicia**: John Rawls argumentaría que las decisiones deberían tomarse desde \"el velo de la ignorancia\", sin conocer nuestra posición social\n",
    "\n",
    "**Evidencia de nuestros datos**: Las simulaciones muestran que el modelo favorece sistemáticamente a mujeres de clase alta y desfavorece a hombres de clase baja, perpetuando las normas sociales de 1912 donde el valor social se basaba en género y estatus económico.\n",
    "\n",
    "#### 2. ¿Cómo balancear eficiencia vs. equidad?\n",
    "\n",
    "**El dilema**: Existe una tensión fundamental entre optimizar la precisión predictiva (eficiencia) y garantizar trato justo a todos los grupos (equidad). Nuestro modelo tiene alta precisión general (78.8%), pero produce disparidades significativas entre grupos.\n",
    "\n",
    "**Trade-offs identificados**:\n",
    "- **Eficiencia alta + Equidad baja**: El modelo actual maximiza precisión pero discrimina\n",
    "- **Eficiencia media + Equidad alta**: Podríamos sacrificar algo de precisión para reducir sesgos\n",
    "- **Imposibilidad matemática**: Las métricas de fairness a menudo son mutuamente incompatibles\n",
    "\n",
    "**Implicaciones prácticas**: En situaciones de emergencia real, ¿es moralmente aceptable usar un sistema sesgado pero eficiente si salva más vidas en total? ¿O la equidad es un principio no negociable?\n",
    "\n",
    "#### 3. ¿Qué valores están implícitos en nuestras métricas?\n",
    "\n",
    "**Valores ocultos en las métricas**:\n",
    "- **Disparidad demográfica**: Asume que todos los grupos deberían tener tasas de predicción positiva similares\n",
    "- **Igualdad de oportunidad**: Prioriza que los \"verdaderos positivos\" sean identificados equitativamente\n",
    "- **Odds equalizados**: Busca equilibrio tanto en aciertos como en errores\n",
    "\n",
    "**El problema**: Estas métricas reflejan concepciones específicas de justicia que pueden no ser universalmente aceptadas. Por ejemplo:\n",
    "- ¿Es más importante no discriminar contra supervivientes reales (igualdad de oportunidad)?\n",
    "- ¿O es más crítico dar a todos la misma probabilidad de ser seleccionados (disparidad demográfica)?\n",
    "\n",
    "#### 4. ¿Perpetúa el modelo injusticias históricas?\n",
    "\n",
    "**Evidencia clara de perpetuación**:\n",
    "Nuestros resultados muestran que el modelo reproduce las jerarquías sociales de 1912:\n",
    "- Las mujeres de primera clase tienen 100% de asignación predicha vs. 55.6% real\n",
    "- Los hombres de tercera clase reciben solo 13% de asignación vs. 24% real\n",
    "- Los ancianos son sistemáticamente mal clasificados debido a muestras pequeñas\n",
    "\n",
    "**Mecanismos de perpetuación**:\n",
    "1. **Sesgo histórico en datos**: Los patrones de supervivencia reflejan normas discriminatorias de la época\n",
    "2. **Amplificación algorítmica**: El modelo puede exagerar estos patrones en sus predicciones\n",
    "3. **Feedback loops**: Si se usara en práctica, reforzaría las mismas desigualdades\n",
    "\n",
    "**La paradoja ética**: El modelo es \"exitoso\" precisamente porque replica fielmente un sistema social injusto. Su precisión proviene de su capacidad de capturar y perpetuar discriminación histórica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3ab015",
   "metadata": {},
   "source": [
    "### B. Contexto Histórico vs. Aplicación Moderna\n",
    "\n",
    "#### 1. Diferencias entre contexto del Titanic (1912) y uso actual\n",
    "\n",
    "**Contexto histórico (1912)**:\n",
    "- **Normas sociales explícitas**: \"Mujeres y niños primero\" era un protocolo social aceptado\n",
    "- **Jerarquías de clase reconocidas**: La estratificación social era explícita y legalmente codificada\n",
    "- **Decisiones humanas**: Las decisiones de supervivencia fueron tomadas por individuos bajo presión extrema\n",
    "- **Recursos limitados**: Genuinamente había escasez de botes salvavidas (solo para ~1/3 de los pasajeros)\n",
    "\n",
    "**Aplicación moderna**:\n",
    "- **Supuesta igualdad**: Las sociedades modernas proclaman igualdad formal ante la ley\n",
    "- **Discriminación implícita**: Los sesgos operan de forma más sutil y están legalmente prohibidos\n",
    "- **Decisiones algorítmicas**: Los sistemas automáticos toman decisiones a escala masiva\n",
    "- **Responsabilidad diffusa**: Es difícil asignar culpabilidad moral a sistemas complejos\n",
    "\n",
    "#### 2. ¿Qué aprendemos sobre sesgos en datos históricos?\n",
    "\n",
    "**Lecciones críticas**:\n",
    "\n",
    "1. **Los datos no son neutrales**: Los datasets históricos son artefactos culturales que capturan los prejuicios de su época\n",
    "2. **La \"precisión\" puede ser problemática**: Un modelo que reproduce fielmente patrones discriminatorios del pasado puede ser técnicamente preciso pero éticamente inaceptable\n",
    "3. **Invisibilidad de la opresión**: Los grupos más marginados pueden estar subrepresentados o completamente ausentes en los datos\n",
    "4. **Normalización de la injusticia**: Lo que era considerado \"normal\" o \"natural\" en el pasado puede ser reconocido como injusto hoy\n",
    "\n",
    "**Evidencia en nuestros datos**:\n",
    "- Las mujeres de tercera clase tenían 50% de supervivencia real, pero nuestro modelo les asigna solo 42.9%\n",
    "- Los hombres de primera clase tenían 36.7% de supervivencia pero el modelo les da 50%\n",
    "- Esto sugiere que incluso los \"hechos históricos\" pueden estar sesgados en los registros\n",
    "\n",
    "#### 3. Paralelos con sistemas de decisión actuales\n",
    "\n",
    "**Sistemas contemporáneos con problemas similares**:\n",
    "\n",
    "**Justicia criminal**:\n",
    "- Algoritmos de evaluación de riesgo que discriminan por raza\n",
    "- Basados en datos históricos de un sistema judicial sesgado\n",
    "- Perpetúan encarcelamiento masivo de minorías\n",
    "\n",
    "**Contratación algorítmica**:\n",
    "- IA que discrimina contra mujeres en roles técnicos\n",
    "- Entrenada con datos de decisiones de contratación históricamente sesgadas\n",
    "- Amazon tuvo que eliminar su sistema de screening de CVs por sesgo de género\n",
    "\n",
    "**Préstamos y seguros**:\n",
    "- Algoritmos que niegan crédito a minorías\n",
    "- Basados en patrones históricos de exclusión financiera\n",
    "- Perpetúan desigualdades económicas intergeneracionales\n",
    "\n",
    "**Salud pública**:\n",
    "- Algoritmos de triaje médico que subestiman la gravedad en pacientes negros\n",
    "- Basados en datos históricos de disparidades en atención médica\n",
    "- Pueden llevar a peores resultados de salud para grupos ya marginados\n",
    "\n",
    "#### 4. Lecciones para datasets contemporáneos\n",
    "\n",
    "**Principios para el manejo ético de datos**:\n",
    "\n",
    "1. **Auditoría histórica**: Examinar las circunstancias sociales y políticas en que se recolectaron los datos\n",
    "2. **Representatividad crítica**: Identificar qué voces y experiencias pueden estar ausentes\n",
    "3. **Contextualización temporal**: Reconocer que las normas sociales evolucionan\n",
    "4. **Impacto diferencial**: Analizar cómo las decisiones algorítmicas afectan diferentes grupos\n",
    "5. **Transparencia sobre limitaciones**: Ser explícito sobre los sesgos conocidos y sus implicaciones\n",
    "\n",
    "**Preguntas críticas para cualquier dataset**:\n",
    "- ¿Quién recopiló estos datos y con qué propósito?\n",
    "- ¿Qué grupos pueden estar subrepresentados o ausentes?\n",
    "- ¿Qué normas sociales de la época se reflejan en los datos?\n",
    "- ¿Cómo podrían perpetuarse injusticias históricas a través del modelo?\n",
    "- ¿Es éticamente aceptable usar estos datos para decisiones que afectan vidas reales?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a61307",
   "metadata": {},
   "source": [
    "### C. Responsabilidad y Transparencia\n",
    "\n",
    "#### 1. ¿A quién deberíamos explicar el modelo?\n",
    "\n",
    "**Stakeholders con derecho a explicaciones**:\n",
    "\n",
    "**Stakeholders primarios (directamente afectados)**:\n",
    "- **Individuos evaluados**: Personas cuyas vidas serían determinadas por el algoritmo\n",
    "- **Familias y comunidades**: Grupos que sufren las consecuencias de decisiones sesgadas\n",
    "- **Grupos protegidos**: Comunidades históricamente discriminadas que pueden ser afectadas desproporcionalmente\n",
    "\n",
    "**Stakeholders secundarios (responsables de implementación)**:\n",
    "- **Operadores del sistema**: Personal que ejecuta las decisiones algorítmicas\n",
    "- **Supervisores y reguladores**: Autoridades responsables de oversight\n",
    "- **Organizaciones implementadoras**: Instituciones que despliegan el sistema\n",
    "\n",
    "**Stakeholders terciarios (sociedad en general)**:\n",
    "- **Público general**: Ciudadanos que viven en una sociedad que usa estos sistemas\n",
    "- **Investigadores y académicos**: Comunidad científica que estudia estos temas\n",
    "- **Formuladores de política**: Legisladores que regulan el uso de IA\n",
    "\n",
    "**Desafíos de explicabilidad por stakeholder**:\n",
    "- **Nivel técnico**: ¿Qué tan profundo debe ser el entendimiento técnico?\n",
    "- **Lenguaje apropiado**: ¿Cómo comunicar conceptos complejos sin jerga?\n",
    "- **Relevancia contextual**: ¿Qué aspectos son más importantes para cada grupo?\n",
    "\n",
    "#### 2. ¿Qué nivel de transparencia es necesario?\n",
    "\n",
    "**Niveles de transparencia (de menor a mayor)**:\n",
    "\n",
    "1. **Transparencia de outcome**: Solo revelar decisiones finales\n",
    "   - *Ejemplo*: \"Usted fue/no fue seleccionado\"\n",
    "   - *Limitaciones*: No permite contestar ni mejorar el sistema\n",
    "\n",
    "2. **Transparencia de proceso**: Explicar pasos generales\n",
    "   - *Ejemplo*: \"Consideramos edad, género, clase social y familia\"\n",
    "   - *Limitaciones*: Puede no revelar sesgos o problemas específicos\n",
    "\n",
    "3. **Transparencia algorítmica**: Revelar el modelo completo\n",
    "   - *Ejemplo*: Mostrar pesos, features, y arquitectura del algoritmo\n",
    "   - *Limitaciones*: Puede ser incomprensible para no-expertos\n",
    "\n",
    "4. **Transparencia de datos**: Revelar datasets y proceso de entrenamiento\n",
    "   - *Ejemplo*: Documentar fuentes, limitaciones, y sesgos conocidos en los datos\n",
    "   - *Limitaciones*: Puede revelar información sensible o propiedad intelectual\n",
    "\n",
    "5. **Transparencia completa**: Código abierto y auditoría pública\n",
    "   - *Ejemplo*: GitHub público con datos, código, y documentación completa\n",
    "   - *Limitaciones*: Puede facilitar gaming del sistema o uso malintencionado\n",
    "\n",
    "**Nuestro caso específico**:\n",
    "Para el modelo del Titanic, argumentamos que se necesita **transparencia completa** porque:\n",
    "- Las decisiones tienen consecuencias fatales\n",
    "- Los sesgos identificados son significativos y sistemáticos\n",
    "- El contexto histórico requiere explicación cuidadosa\n",
    "- La investigación académica se beneficia de reproducibilidad completa\n",
    "\n",
    "#### 3. ¿Quién debería decidir los trade-offs?\n",
    "\n",
    "**El problema de la legitimidad democrática**:\n",
    "Los algoritmos de ML implican decisiones de valor que tradicionalmente han sido del dominio de procesos democráticos. ¿Quién tiene la autoridad moral para decidir cómo balancear eficiencia vs. equidad?\n",
    "\n",
    "**Opciones de gobernanza**:\n",
    "\n",
    "**Modelo tecnocrático**:\n",
    "- *Quién decide*: Expertos técnicos y científicos de datos\n",
    "- *Ventajas*: Conocimiento técnico profundo, eficiencia\n",
    "- *Desventajas*: Falta de legitimidad democrática, sesgos profesionales\n",
    "\n",
    "**Modelo democrático directo**:\n",
    "- *Quién decide*: Votación pública o referendums\n",
    "- *Ventajas*: Legitimidad democrática máxima\n",
    "- *Desventajas*: Complejidad técnica, potencial para demagogia\n",
    "\n",
    "**Modelo de representación**:\n",
    "- *Quién decide*: Legisladores electos y reguladores nombrados\n",
    "- *Ventajas*: Balance entre expertise y legitimidad\n",
    "- *Desventajas*: Posible captura por intereses especiales\n",
    "\n",
    "**Modelo participativo**:\n",
    "- *Quién decide*: Comités ciudadanos deliberativos con representación diversa\n",
    "- *Ventajas*: Incluye voces afectadas, proceso educativo\n",
    "- *Desventajas*: Lento, potencialmente no representativo\n",
    "\n",
    "**Modelo de stakeholders múltiples**:\n",
    "- *Quién decide*: Coalición de grupos afectados, expertos, y reguladores\n",
    "- *Ventajas*: Múltiples perspectivas, legitimidad compartida\n",
    "- *Desventajas*: Proceso complejo, posibles deadlocks\n",
    "\n",
    "**Nuestra recomendación**:\n",
    "Para sistemas con impacto social significativo como nuestro modelo del Titanic, proponemos un **modelo participativo modificado**:\n",
    "1. Comité de ética con representación diversa (incluye grupos afectados)\n",
    "2. Revisión técnica independiente por expertos\n",
    "3. Período de comentario público\n",
    "4. Supervisión regulatoria continua\n",
    "5. Mecanismos de apelación y recurso\n",
    "\n",
    "#### 4. Rol de los data scientists en decisiones éticas\n",
    "\n",
    "**Responsabilidades éticas de los profesionales**:\n",
    "\n",
    "**Responsabilidades mínimas (profesionales)**:\n",
    "- Documentar sesgos conocidos y limitaciones del modelo\n",
    "- Usar mejores prácticas técnicas para evaluación de fairness\n",
    "- Comunicar incertidumbre y rangos de confianza\n",
    "- Rechazar proyectos que claramente perpetúan discriminación\n",
    "\n",
    "**Responsabilidades extendidas (sociales)**:\n",
    "- Abogar por transparencia y accountability en organizaciones\n",
    "- Educar a stakeholders sobre implicaciones éticas\n",
    "- Participar en desarrollo de estándares profesionales\n",
    "- Considerar impactos sociales más allá de métricas técnicas\n",
    "\n",
    "**Responsabilidades aspiracionales (transformativas)**:\n",
    "- Trabajar activamente para reducir desigualdades sociales\n",
    "- Desarrollar tecnologías que empoderan a comunidades marginadas\n",
    "- Formar parte de movimientos de justicia social\n",
    "- Redefinir el éxito más allá de métricas de negocio\n",
    "\n",
    "**Tensiones y dilemas**:\n",
    "\n",
    "*Conflicto empleador vs. sociedad*:\n",
    "- ¿Qué hacer cuando el empleador quiere implementar un sistema sesgado?\n",
    "- ¿Cuándo es ético \"hacer sonar la alarma\" públicamente?\n",
    "\n",
    "*Límites del expertise*:\n",
    "- ¿Hasta dónde se extiende la competencia técnica vs. juicio moral?\n",
    "- ¿Cómo evitar tecnocracia sin abandonar responsabilidad profesional?\n",
    "\n",
    "*Efectividad vs. pureza*:\n",
    "- ¿Es mejor trabajar dentro de sistemas imperfectos para mejorarlos gradualmente?\n",
    "- ¿O rechazar completamente participación en sistemas éticamente problemáticos?\n",
    "\n",
    "**Nuestro posicionamiento**:\n",
    "Como desarrolladores de este modelo del Titanic, reconocemos nuestra responsabilidad de:\n",
    "1. **Transparencia completa**: Documentar todos los sesgos identificados\n",
    "2. **Educación**: Explicar las implicaciones éticas a audiencias técnicas y generales\n",
    "3. **Advocacy**: Argumentar contra el uso de este modelo para decisiones reales sin modificaciones éticas\n",
    "4. **Investigación continua**: Contribuir al desarrollo de métodos más equitativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea9498d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 RESUMEN EJECUTIVO - PARTE 1: ANÁLISIS ÉTICO Y DE FAIRNESS\n",
      "================================================================================\n",
      "\\n🚨 SESGOS CRÍTICOS DETECTADOS:\n",
      "--------------------------------------------------\n",
      "\\n📊 GÉNERO:\n",
      "   • Disparidad demográfica: 0.253 (umbral crítico: <0.8)\n",
      "   • Igualdad de oportunidad: 0.481 (umbral crítico: <0.8)\n",
      "   • Evaluación: Sesgo severo favorable a mujeres\n",
      "\\n📊 CLASE:\n",
      "   • Disparidad demográfica: 0.322 (umbral crítico: <0.8)\n",
      "   • Igualdad de oportunidad: 0.556 (umbral crítico: <0.8)\n",
      "   • Evaluación: Sesgo severo desfavorable a tercera clase\n",
      "\\n📊 EDAD:\n",
      "   • Disparidad demográfica: 0.644 (umbral crítico: <0.8)\n",
      "   • Igualdad de oportunidad: 0.734 (umbral crítico: <0.8)\n",
      "   • Evaluación: Sesgo moderado favorable a niños\n",
      "\\n🔍 HALLAZGOS INTERSECCIONALES:\n",
      "--------------------------------------------------\n",
      "Grupos más afectados por sesgos:\n",
      "   • male_Class2_Elder (sesgo: -1.000)\n",
      "   • male_Class1_Elder (sesgo: +0.250)\n",
      "   • female_Class1_Child (sesgo: +0.250)\n",
      "\\nObservaciones clave:\n",
      "   • Grupos con muestras pequeñas tienen sesgos extremos\n",
      "   • Intersección de género y clase amplifica disparidades\n",
      "   • Ancianos particularmente vulnerables a errores del modelo\n",
      "\\n🚢 SIMULACIÓN DE DECISIONES:\n",
      "--------------------------------------------------\n",
      "Escenario de capacidad limitada (30%):\n",
      "   • Tercera Clase Penalizada: 13% asignado vs 24% real (-11%)\n",
      "   • Primera Clase Favorecida: 51% asignado vs 56% real (-4%)\n",
      "\\nEscenario de capacidad alta (70%):\n",
      "   • Sobrecompensación Generalizada: Todos los grupos favorecidos\n",
      "   • Amplificación Sesgos: Diferencias se magnifican con más recursos\n",
      "\\n🤔 DILEMAS ÉTICOS IDENTIFICADOS:\n",
      "--------------------------------------------------\n",
      "Preguntas fundamentales:\n",
      "   • ¿Es ético predecir quién \"merece\" sobrevivir?\n",
      "   • ¿Cómo balancear eficiencia vs equidad?\n",
      "   • ¿Qué valores están implícitos en nuestras métricas?\n",
      "   • ¿Perpetúa el modelo injusticias históricas?\n",
      "\\nRequerimientos de responsabilidad:\n",
      "   • Necesidad de transparencia completa\n",
      "   • Participación de stakeholders afectados en decisiones\n",
      "   • Responsabilidad ética de data scientists\n",
      "   • Supervisión regulatoria y mecanismos de apelación\n",
      "\\n\\n⚖️ CONCLUSIONES PRINCIPALES:\n",
      "==================================================\n",
      "\\n1. 🔴 SESGOS SISTÉMICOS: El modelo reproduce y amplifica desigualdades históricas\n",
      "   - Todos los grupos protegidos muestran sesgos significativos\n",
      "   - Los sesgos se magnifican en análisis interseccional\n",
      "   - Las simulaciones confirman impacto discriminatorio en decisiones reales\n",
      "\\n2. 📊 IMPOSIBILIDAD DE FAIRNESS PERFECTA: Las métricas de equidad son mutuamente incompatibles\n",
      "   - Mejorar disparidad demográfica puede empeorar igualdad de oportunidad\n",
      "   - Diferentes definiciones de justicia llevan a resultados conflictivos\n",
      "   - Los trade-offs requieren decisiones de valor explícitas\n",
      "\\n3. 🏛️ PERPETUACIÓN DE INJUSTICIAS HISTÓRICAS: El modelo codifica normas discriminatorias de 1912\n",
      "   - Los datos reflejan sistemas sociales explícitamente desiguales\n",
      "   - La 'precisión' técnica proviene de replicar discriminación histórica\n",
      "   - Uso sin modificaciones perpetuaría injusticias en contextos modernos\n",
      "\\n4. 🤝 NECESIDAD DE GOBERNANZA ÉTICA: Decisiones algorítmicas requieren supervisión democrática\n",
      "   - Transparencia completa es esencial para accountability\n",
      "   - Stakeholders afectados deben participar en decisiones de diseño\n",
      "   - Data scientists tienen responsabilidades éticas extendidas\n",
      "\\n5. ⚠️ RIESGOS DE IMPLEMENTACIÓN: Uso irresponsable podría causar daño social significativo\n",
      "   - Automatización de discriminación a escala masiva\n",
      "   - Legitimación de sesgos bajo apariencia de objetividad\n",
      "   - Erosión de principios de dignidad humana y equidad\n",
      "\\n\\n🎯 RECOMENDACIONES PARA TRABAJO FUTURO:\n",
      "==================================================\n",
      "\\n1. 🔧 MITIGACIÓN TÉCNICA:\n",
      "   • Implementar técnicas de debiasing y fairness constraints\n",
      "   • Desarrollar métricas de fairness contextualizadas\n",
      "   • Crear sistemas de detección automática de sesgos\n",
      "\\n2. 📋 GOBERNANZA Y POLICY:\n",
      "   • Establecer comités de ética con representación diversa\n",
      "   • Desarrollar estándares de transparencia algorítmica\n",
      "   • Crear mecanismos de auditoría y apelación\n",
      "\\n3. 🎓 EDUCACIÓN Y CONCIENCIA:\n",
      "   • Integrar ética de IA en curricula de ciencias de datos\n",
      "   • Educar al público sobre sesgos algorítmicos\n",
      "   • Formar data scientists en responsabilidad social\n",
      "\\n4. 🔬 INVESTIGACIÓN FUNDAMENTAL:\n",
      "   • Desarrollar nuevas definiciones de fairness\n",
      "   • Investigar impactos sociales a largo plazo\n",
      "   • Crear métodos para datasets históricos sesgados\n",
      "\\n\\n================================================================================\n",
      "FIN DE LA PARTE 1: ANÁLISIS ÉTICO Y DE FAIRNESS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# RESUMEN EJECUTIVO Y CONCLUSIONES DE LA PARTE 1\n",
    "\n",
    "def generate_executive_summary():\n",
    "    \"\"\"\n",
    "    Genera un resumen ejecutivo completo del análisis de fairness\n",
    "    \"\"\"\n",
    "    \n",
    "    executive_summary = {\n",
    "        'sesgos_detectados': {\n",
    "            'género': {\n",
    "                'disparidad_demográfica': 0.253,  # ratio\n",
    "                'igualdad_oportunidad': 0.481,   # ratio  \n",
    "                'descripción': 'Sesgo severo favorable a mujeres'\n",
    "            },\n",
    "            'clase': {\n",
    "                'disparidad_demográfica': 0.322,  # ratio entre clase 3 y 1\n",
    "                'igualdad_oportunidad': 0.556,   # ratio entre clase 3 y 2\n",
    "                'descripción': 'Sesgo severo desfavorable a tercera clase'\n",
    "            },\n",
    "            'edad': {\n",
    "                'disparidad_demográfica': 0.644,  # ratio entre adultos y niños\n",
    "                'igualdad_oportunidad': 0.734,   # ratio entre adultos y niños\n",
    "                'descripción': 'Sesgo moderado favorable a niños'\n",
    "            }\n",
    "        },\n",
    "        'impacto_interseccional': {\n",
    "            'grupos_más_desfavorecidos': [\n",
    "                'male_Class2_Elder (sesgo: -1.000)',\n",
    "                'male_Class1_Elder (sesgo: +0.250)', \n",
    "                'female_Class1_Child (sesgo: +0.250)'\n",
    "            ],\n",
    "            'observaciones': [\n",
    "                'Grupos con muestras pequeñas tienen sesgos extremos',\n",
    "                'Intersección de género y clase amplifica disparidades',\n",
    "                'Ancianos particularmente vulnerables a errores del modelo'\n",
    "            ]\n",
    "        },\n",
    "        'simulación_decisiones': {\n",
    "            'escenario_30_capacidad': {\n",
    "                'tercera_clase_penalizada': '13% asignado vs 24% real (-11%)',\n",
    "                'primera_clase_favorecida': '51% asignado vs 56% real (-4%)'\n",
    "            },\n",
    "            'escenario_70_capacidad': {\n",
    "                'sobrecompensación_generalizada': 'Todos los grupos favorecidos',\n",
    "                'amplificación_sesgos': 'Diferencias se magnifican con más recursos'\n",
    "            }\n",
    "        },\n",
    "        'dilemas_éticos': {\n",
    "            'fundamentales': [\n",
    "                '¿Es ético predecir quién \"merece\" sobrevivir?',\n",
    "                '¿Cómo balancear eficiencia vs equidad?',\n",
    "                '¿Qué valores están implícitos en nuestras métricas?',\n",
    "                '¿Perpetúa el modelo injusticias históricas?'\n",
    "            ],\n",
    "            'responsabilidad': [\n",
    "                'Necesidad de transparencia completa',\n",
    "                'Participación de stakeholders afectados en decisiones',\n",
    "                'Responsabilidad ética de data scientists',\n",
    "                'Supervisión regulatoria y mecanismos de apelación'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return executive_summary\n",
    "\n",
    "# Generar y mostrar resumen\n",
    "executive_summary = generate_executive_summary()\n",
    "\n",
    "print(\"📋 RESUMEN EJECUTIVO - PARTE 1: ANÁLISIS ÉTICO Y DE FAIRNESS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\\\n🚨 SESGOS CRÍTICOS DETECTADOS:\")\n",
    "print(\"-\" * 50)\n",
    "for category, data in executive_summary['sesgos_detectados'].items():\n",
    "    print(f\"\\\\n📊 {category.upper()}:\")\n",
    "    print(f\"   • Disparidad demográfica: {data['disparidad_demográfica']:.3f} (umbral crítico: <0.8)\")\n",
    "    print(f\"   • Igualdad de oportunidad: {data['igualdad_oportunidad']:.3f} (umbral crítico: <0.8)\")\n",
    "    print(f\"   • Evaluación: {data['descripción']}\")\n",
    "\n",
    "print(\"\\\\n🔍 HALLAZGOS INTERSECCIONALES:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Grupos más afectados por sesgos:\")\n",
    "for grupo in executive_summary['impacto_interseccional']['grupos_más_desfavorecidos']:\n",
    "    print(f\"   • {grupo}\")\n",
    "\n",
    "print(\"\\\\nObservaciones clave:\")\n",
    "for obs in executive_summary['impacto_interseccional']['observaciones']:\n",
    "    print(f\"   • {obs}\")\n",
    "\n",
    "print(\"\\\\n🚢 SIMULACIÓN DE DECISIONES:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Escenario de capacidad limitada (30%):\")\n",
    "for key, value in executive_summary['simulación_decisiones']['escenario_30_capacidad'].items():\n",
    "    print(f\"   • {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "print(\"\\\\nEscenario de capacidad alta (70%):\")\n",
    "for key, value in executive_summary['simulación_decisiones']['escenario_70_capacidad'].items():\n",
    "    print(f\"   • {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "print(\"\\\\n🤔 DILEMAS ÉTICOS IDENTIFICADOS:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Preguntas fundamentales:\")\n",
    "for dilema in executive_summary['dilemas_éticos']['fundamentales']:\n",
    "    print(f\"   • {dilema}\")\n",
    "\n",
    "print(\"\\\\nRequerimientos de responsabilidad:\")\n",
    "for req in executive_summary['dilemas_éticos']['responsabilidad']:\n",
    "    print(f\"   • {req}\")\n",
    "\n",
    "print(\"\\\\n\\\\n⚖️ CONCLUSIONES PRINCIPALES:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\\\n1. 🔴 SESGOS SISTÉMICOS: El modelo reproduce y amplifica desigualdades históricas\")\n",
    "print(\"   - Todos los grupos protegidos muestran sesgos significativos\")\n",
    "print(\"   - Los sesgos se magnifican en análisis interseccional\")\n",
    "print(\"   - Las simulaciones confirman impacto discriminatorio en decisiones reales\")\n",
    "\n",
    "print(\"\\\\n2. 📊 IMPOSIBILIDAD DE FAIRNESS PERFECTA: Las métricas de equidad son mutuamente incompatibles\")\n",
    "print(\"   - Mejorar disparidad demográfica puede empeorar igualdad de oportunidad\")\n",
    "print(\"   - Diferentes definiciones de justicia llevan a resultados conflictivos\")\n",
    "print(\"   - Los trade-offs requieren decisiones de valor explícitas\")\n",
    "\n",
    "print(\"\\\\n3. 🏛️ PERPETUACIÓN DE INJUSTICIAS HISTÓRICAS: El modelo codifica normas discriminatorias de 1912\")\n",
    "print(\"   - Los datos reflejan sistemas sociales explícitamente desiguales\")\n",
    "print(\"   - La 'precisión' técnica proviene de replicar discriminación histórica\")\n",
    "print(\"   - Uso sin modificaciones perpetuaría injusticias en contextos modernos\")\n",
    "\n",
    "print(\"\\\\n4. 🤝 NECESIDAD DE GOBERNANZA ÉTICA: Decisiones algorítmicas requieren supervisión democrática\")\n",
    "print(\"   - Transparencia completa es esencial para accountability\")\n",
    "print(\"   - Stakeholders afectados deben participar en decisiones de diseño\")\n",
    "print(\"   - Data scientists tienen responsabilidades éticas extendidas\")\n",
    "\n",
    "print(\"\\\\n5. ⚠️ RIESGOS DE IMPLEMENTACIÓN: Uso irresponsable podría causar daño social significativo\")\n",
    "print(\"   - Automatización de discriminación a escala masiva\")\n",
    "print(\"   - Legitimación de sesgos bajo apariencia de objetividad\")\n",
    "print(\"   - Erosión de principios de dignidad humana y equidad\")\n",
    "\n",
    "print(\"\\\\n\\\\n🎯 RECOMENDACIONES PARA TRABAJO FUTURO:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\\\n1. 🔧 MITIGACIÓN TÉCNICA:\")\n",
    "print(\"   • Implementar técnicas de debiasing y fairness constraints\")\n",
    "print(\"   • Desarrollar métricas de fairness contextualizadas\")\n",
    "print(\"   • Crear sistemas de detección automática de sesgos\")\n",
    "\n",
    "print(\"\\\\n2. 📋 GOBERNANZA Y POLICY:\")\n",
    "print(\"   • Establecer comités de ética con representación diversa\")\n",
    "print(\"   • Desarrollar estándares de transparencia algorítmica\")\n",
    "print(\"   • Crear mecanismos de auditoría y apelación\")\n",
    "\n",
    "print(\"\\\\n3. 🎓 EDUCACIÓN Y CONCIENCIA:\")\n",
    "print(\"   • Integrar ética de IA en curricula de ciencias de datos\")\n",
    "print(\"   • Educar al público sobre sesgos algorítmicos\")\n",
    "print(\"   • Formar data scientists en responsabilidad social\")\n",
    "\n",
    "print(\"\\\\n4. 🔬 INVESTIGACIÓN FUNDAMENTAL:\")\n",
    "print(\"   • Desarrollar nuevas definiciones de fairness\")\n",
    "print(\"   • Investigar impactos sociales a largo plazo\")\n",
    "print(\"   • Crear métodos para datasets históricos sesgados\")\n",
    "\n",
    "print(\"\\\\n\\\\n\" + \"=\"*80)\n",
    "print(\"FIN DE LA PARTE 1: ANÁLISIS ÉTICO Y DE FAIRNESS\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
